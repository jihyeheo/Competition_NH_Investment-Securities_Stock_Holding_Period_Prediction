{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_row\", 100)\n",
    "pd.set_option(\"display.max_column\", 100)\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"C:/Users/hu612/Desktop/School/sooda/Project/팀과제/민수서영우철/data/stk_hld_train.csv\")\n",
    "test = pd.read_csv(\"C:/Users/hu612/Desktop/School/sooda/Project/팀과제/민수서영우철/data/stk_hld_test.csv\")\n",
    "cus = pd.read_csv(\"C:/Users/hu612/Desktop/School/sooda/Project/팀과제/민수서영우철/data/cus_info.csv\")\n",
    "iem = pd.read_csv(\"C:/Users/hu612/Desktop/School/sooda/Project/팀과제/민수서영우철/data/iem_info_20210902.csv\")\n",
    "hist = pd.read_csv(\"C:/Users/hu612/Desktop/School/sooda/Project/팀과제/민수서영우철/data/stk_bnc_hist.csv\")\n",
    "submission = pd.read_csv(\"C:/Users/hu612/Desktop/School/sooda/Project/팀과제/민수서영우철/data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_id</th>\n",
       "      <th>iem_cd</th>\n",
       "      <th>byn_dt</th>\n",
       "      <th>hold_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A006360</td>\n",
       "      <td>20180726</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A005930</td>\n",
       "      <td>20180131</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A005070</td>\n",
       "      <td>20180517</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              act_id   iem_cd    byn_dt  \\\n",
       "0  0ad104dbed99be0cd858aa772765ddedade554601a981b...  A006360  20180726   \n",
       "1  0ad104dbed99be0cd858aa772765ddedade554601a981b...  A005930  20180131   \n",
       "2  0ad104dbed99be0cd858aa772765ddedade554601a981b...  A005070  20180517   \n",
       "\n",
       "   hold_d  \n",
       "0      11  \n",
       "1      80  \n",
       "2       5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_id</th>\n",
       "      <th>iem_cd</th>\n",
       "      <th>byn_dt</th>\n",
       "      <th>hist_d</th>\n",
       "      <th>submit_id</th>\n",
       "      <th>hold_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A032640</td>\n",
       "      <td>20200522</td>\n",
       "      <td>153</td>\n",
       "      <td>IDX00001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A160600</td>\n",
       "      <td>20190823</td>\n",
       "      <td>335</td>\n",
       "      <td>IDX00002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A234340</td>\n",
       "      <td>20200611</td>\n",
       "      <td>139</td>\n",
       "      <td>IDX00003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              act_id   iem_cd    byn_dt  \\\n",
       "0  0ad104dbed99be0cd858aa772765ddedade554601a981b...  A032640  20200522   \n",
       "1  0ad104dbed99be0cd858aa772765ddedade554601a981b...  A160600  20190823   \n",
       "2  0ad104dbed99be0cd858aa772765ddedade554601a981b...  A234340  20200611   \n",
       "\n",
       "   hist_d submit_id  hold_d  \n",
       "0     153  IDX00001       0  \n",
       "1     335  IDX00002       0  \n",
       "2     139  IDX00003       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"hist_d\"] = train[\"hold_d\"]*0.877\n",
    "train.hist_d = np.trunc(train[\"hist_d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_id</th>\n",
       "      <th>iem_cd</th>\n",
       "      <th>byn_dt</th>\n",
       "      <th>hold_d</th>\n",
       "      <th>hist_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A006360</td>\n",
       "      <td>20180726</td>\n",
       "      <td>11</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A005930</td>\n",
       "      <td>20180131</td>\n",
       "      <td>80</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A005070</td>\n",
       "      <td>20180517</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A003520</td>\n",
       "      <td>20201112</td>\n",
       "      <td>22</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A002310</td>\n",
       "      <td>20180905</td>\n",
       "      <td>324</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681467</th>\n",
       "      <td>4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...</td>\n",
       "      <td>A260660</td>\n",
       "      <td>20180831</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681468</th>\n",
       "      <td>4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...</td>\n",
       "      <td>A271980</td>\n",
       "      <td>20201027</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681469</th>\n",
       "      <td>4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...</td>\n",
       "      <td>A289080</td>\n",
       "      <td>20181121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681470</th>\n",
       "      <td>4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...</td>\n",
       "      <td>A307930</td>\n",
       "      <td>20200214</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681471</th>\n",
       "      <td>4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...</td>\n",
       "      <td>A308100</td>\n",
       "      <td>20200116</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>681472 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   act_id   iem_cd    byn_dt  \\\n",
       "0       0ad104dbed99be0cd858aa772765ddedade554601a981b...  A006360  20180726   \n",
       "1       0ad104dbed99be0cd858aa772765ddedade554601a981b...  A005930  20180131   \n",
       "2       0ad104dbed99be0cd858aa772765ddedade554601a981b...  A005070  20180517   \n",
       "3       0ad104dbed99be0cd858aa772765ddedade554601a981b...  A003520  20201112   \n",
       "4       0ad104dbed99be0cd858aa772765ddedade554601a981b...  A002310  20180905   \n",
       "...                                                   ...      ...       ...   \n",
       "681467  4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...  A260660  20180831   \n",
       "681468  4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...  A271980  20201027   \n",
       "681469  4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...  A289080  20181121   \n",
       "681470  4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...  A307930  20200214   \n",
       "681471  4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...  A308100  20200116   \n",
       "\n",
       "        hold_d  hist_d  \n",
       "0           11     9.0  \n",
       "1           80    70.0  \n",
       "2            5     4.0  \n",
       "3           22    19.0  \n",
       "4          324   284.0  \n",
       "...        ...     ...  \n",
       "681467       1     0.0  \n",
       "681468       1     0.0  \n",
       "681469       1     0.0  \n",
       "681470       1     0.0  \n",
       "681471       1     0.0  \n",
       "\n",
       "[681472 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train과 test에 고객정보(cus_info)와 주식정보(iem_info)를 추가하겠습니다.\n",
    "\n",
    "train_data = pd.merge(train, cus, how = \"left\", on = [\"act_id\"])\n",
    "train_data = pd.merge(train_data, iem, how = \"left\", on = [\"iem_cd\"])\n",
    "\n",
    "test_data = pd.merge(test, cus, how = \"left\", on = [\"act_id\"])\n",
    "test_data = pd.merge(test_data, iem, how = \"left\", on = [\"iem_cd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681472, 18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data에서 Y값을 추출한 후 hold_d column을 지워주겠습니다.\n",
    "\n",
    "train_label = train_data[\"hold_d\"]\n",
    "train_data.drop([\"hold_d\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가적으로 약간의 전처리를 통해 train data와 test data를 구성하겠습니다.\n",
    "\n",
    "hist[\"stk_p\"] = hist[\"tot_aet_amt\"] / hist[\"bnc_qty\"]\n",
    "hist = hist.fillna(0)\n",
    "\n",
    "train_data = pd.merge(train_data, hist, how = \"left\", on = [\"act_id\", \"iem_cd\"])\n",
    "train_data = train_data[(train_data[\"byn_dt\"] == train_data[\"bse_dt\"])]\n",
    "train_data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "test_data = pd.merge(test_data, hist, how = \"left\", on = [\"act_id\", \"iem_cd\"])\n",
    "test_data = test_data[(test_data[\"byn_dt\"] == test_data[\"bse_dt\"])]\n",
    "test_data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "train_data = train_data.drop([\"act_id\", \"iem_cd\", \"byn_dt\", \"bse_dt\"], axis = 1)\n",
    "test_data = test_data.drop([\"act_id\", \"iem_cd\", \"byn_dt\", \"submit_id\", \"hold_d\", \"bse_dt\"], axis = 1)\n",
    "\n",
    "L_encoder = LabelEncoder()\n",
    "L_encoder.fit(iem[\"iem_krl_nm\"])\n",
    "train_data[\"iem_krl_nm\"] = L_encoder.transform(train_data[\"iem_krl_nm\"])\n",
    "test_data[\"iem_krl_nm\"] = L_encoder.transform(test_data[\"iem_krl_nm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hist_d</th>\n",
       "      <th>sex_dit_cd</th>\n",
       "      <th>cus_age_stn_cd</th>\n",
       "      <th>ivs_icn_cd</th>\n",
       "      <th>cus_aet_stn_cd</th>\n",
       "      <th>mrz_pdt_tp_sgm_cd</th>\n",
       "      <th>lsg_sgm_cd</th>\n",
       "      <th>tco_cus_grd_cd</th>\n",
       "      <th>tot_ivs_te_sgm_cd</th>\n",
       "      <th>mrz_btp_dit_cd</th>\n",
       "      <th>iem_krl_nm</th>\n",
       "      <th>btp_cfc_cd</th>\n",
       "      <th>mkt_pr_tal_scl_tp_cd</th>\n",
       "      <th>stk_dit_cd</th>\n",
       "      <th>bnc_qty</th>\n",
       "      <th>tot_aet_amt</th>\n",
       "      <th>stk_par_pr</th>\n",
       "      <th>stk_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>274.0</td>\n",
       "      <td>11782000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>43000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1361</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4990000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2495000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2530</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>786.0</td>\n",
       "      <td>14619600.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>18600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hist_d  sex_dit_cd  cus_age_stn_cd  ivs_icn_cd  cus_aet_stn_cd  \\\n",
       "0     9.0           1               9           3               2   \n",
       "1    70.0           1               9           3               2   \n",
       "2     4.0           1               9           3               2   \n",
       "\n",
       "   mrz_pdt_tp_sgm_cd  lsg_sgm_cd  tco_cus_grd_cd  tot_ivs_te_sgm_cd  \\\n",
       "0                  2           9               5                  5   \n",
       "1                  2           9               5                  5   \n",
       "2                  2           9               5                  5   \n",
       "\n",
       "   mrz_btp_dit_cd  iem_krl_nm  btp_cfc_cd  mkt_pr_tal_scl_tp_cd  stk_dit_cd  \\\n",
       "0               8         101           1                     1           1   \n",
       "1               8        1361           9                     1           1   \n",
       "2               8        2530          12                     2          99   \n",
       "\n",
       "   bnc_qty  tot_aet_amt  stk_par_pr      stk_p  \n",
       "0    274.0   11782000.0      5000.0    43000.0  \n",
       "1      2.0    4990000.0      5000.0  2495000.0  \n",
       "2    786.0   14619600.0      1000.0    18600.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hist_d</th>\n",
       "      <th>sex_dit_cd</th>\n",
       "      <th>cus_age_stn_cd</th>\n",
       "      <th>ivs_icn_cd</th>\n",
       "      <th>cus_aet_stn_cd</th>\n",
       "      <th>mrz_pdt_tp_sgm_cd</th>\n",
       "      <th>lsg_sgm_cd</th>\n",
       "      <th>tco_cus_grd_cd</th>\n",
       "      <th>tot_ivs_te_sgm_cd</th>\n",
       "      <th>mrz_btp_dit_cd</th>\n",
       "      <th>iem_krl_nm</th>\n",
       "      <th>btp_cfc_cd</th>\n",
       "      <th>mkt_pr_tal_scl_tp_cd</th>\n",
       "      <th>stk_dit_cd</th>\n",
       "      <th>bnc_qty</th>\n",
       "      <th>tot_aet_amt</th>\n",
       "      <th>stk_par_pr</th>\n",
       "      <th>stk_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>274.0</td>\n",
       "      <td>11782000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>43000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1361</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4990000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2495000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2530</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>786.0</td>\n",
       "      <td>14619600.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>18600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1969</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>462000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>7700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>284.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1696</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>183.0</td>\n",
       "      <td>8125200.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>44400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681467</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1752</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>199.0</td>\n",
       "      <td>3532250.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>17750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681468</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2344</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>488.0</td>\n",
       "      <td>22960400.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>47050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681469</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>521</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>2210.0</td>\n",
       "      <td>9204650.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>4165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681470</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2460</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>285.0</td>\n",
       "      <td>2721750.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>9550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681471</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>750</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>310.0</td>\n",
       "      <td>4030000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>13000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>681472 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hist_d  sex_dit_cd  cus_age_stn_cd  ivs_icn_cd  cus_aet_stn_cd  \\\n",
       "0          9.0           1               9           3               2   \n",
       "1         70.0           1               9           3               2   \n",
       "2          4.0           1               9           3               2   \n",
       "3         19.0           1               9           3               2   \n",
       "4        284.0           1               9           3               2   \n",
       "...        ...         ...             ...         ...             ...   \n",
       "681467     0.0           1               4           4               2   \n",
       "681468     0.0           1               4           4               2   \n",
       "681469     0.0           1               4           4               2   \n",
       "681470     0.0           1               4           4               2   \n",
       "681471     0.0           1               4           4               2   \n",
       "\n",
       "        mrz_pdt_tp_sgm_cd  lsg_sgm_cd  tco_cus_grd_cd  tot_ivs_te_sgm_cd  \\\n",
       "0                       2           9               5                  5   \n",
       "1                       2           9               5                  5   \n",
       "2                       2           9               5                  5   \n",
       "3                       2           9               5                  5   \n",
       "4                       2           9               5                  5   \n",
       "...                   ...         ...             ...                ...   \n",
       "681467                  2           3               4                  3   \n",
       "681468                  2           3               4                  3   \n",
       "681469                  2           3               4                  3   \n",
       "681470                  2           3               4                  3   \n",
       "681471                  2           3               4                  3   \n",
       "\n",
       "        mrz_btp_dit_cd  iem_krl_nm  btp_cfc_cd  mkt_pr_tal_scl_tp_cd  \\\n",
       "0                    8         101           1                     1   \n",
       "1                    8        1361           9                     1   \n",
       "2                    8        2530          12                     2   \n",
       "3                    8        1969           8                     2   \n",
       "4                    8        1696          10                     3   \n",
       "...                ...         ...         ...                   ...   \n",
       "681467               8        1752          10                     3   \n",
       "681468               8        2344           8                     2   \n",
       "681469               8         521           2                     2   \n",
       "681470               8        2460           2                     3   \n",
       "681471               8         750           7                     3   \n",
       "\n",
       "        stk_dit_cd  bnc_qty  tot_aet_amt  stk_par_pr      stk_p  \n",
       "0                1    274.0   11782000.0      5000.0    43000.0  \n",
       "1                1      2.0    4990000.0      5000.0  2495000.0  \n",
       "2               99    786.0   14619600.0      1000.0    18600.0  \n",
       "3                1     60.0     462000.0       500.0     7700.0  \n",
       "4               99    183.0    8125200.0      5000.0    44400.0  \n",
       "...            ...      ...          ...         ...        ...  \n",
       "681467          99    199.0    3532250.0       500.0    17750.0  \n",
       "681468          99    488.0   22960400.0       500.0    47050.0  \n",
       "681469          99   2210.0    9204650.0       500.0     4165.0  \n",
       "681470          99    285.0    2721750.0       500.0     9550.0  \n",
       "681471          99    310.0    4030000.0       500.0    13000.0  \n",
       "\n",
       "[681472 rows x 18 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hist_d</th>\n",
       "      <th>sex_dit_cd</th>\n",
       "      <th>cus_age_stn_cd</th>\n",
       "      <th>ivs_icn_cd</th>\n",
       "      <th>cus_aet_stn_cd</th>\n",
       "      <th>mrz_pdt_tp_sgm_cd</th>\n",
       "      <th>lsg_sgm_cd</th>\n",
       "      <th>tco_cus_grd_cd</th>\n",
       "      <th>tot_ivs_te_sgm_cd</th>\n",
       "      <th>mrz_btp_dit_cd</th>\n",
       "      <th>iem_krl_nm</th>\n",
       "      <th>btp_cfc_cd</th>\n",
       "      <th>mkt_pr_tal_scl_tp_cd</th>\n",
       "      <th>stk_dit_cd</th>\n",
       "      <th>bnc_qty</th>\n",
       "      <th>tot_aet_amt</th>\n",
       "      <th>stk_par_pr</th>\n",
       "      <th>stk_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>418</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>300.0</td>\n",
       "      <td>3945000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>13150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>335</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2230</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>198.0</td>\n",
       "      <td>2524500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>12750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1515</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>138.0</td>\n",
       "      <td>4291800.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>31100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hist_d  sex_dit_cd  cus_age_stn_cd  ivs_icn_cd  cus_aet_stn_cd  \\\n",
       "0     153           1               9           3               2   \n",
       "1     335           1               9           3               2   \n",
       "2     139           1               9           3               2   \n",
       "\n",
       "   mrz_pdt_tp_sgm_cd  lsg_sgm_cd  tco_cus_grd_cd  tot_ivs_te_sgm_cd  \\\n",
       "0                  2           9               5                  5   \n",
       "1                  2           9               5                  5   \n",
       "2                  2           9               5                  5   \n",
       "\n",
       "   mrz_btp_dit_cd  iem_krl_nm  btp_cfc_cd  mkt_pr_tal_scl_tp_cd  stk_dit_cd  \\\n",
       "0               8         418           4                     1           1   \n",
       "1               8        2230          10                     3          99   \n",
       "2               8        1515          13                     2          99   \n",
       "\n",
       "   bnc_qty  tot_aet_amt  stk_par_pr    stk_p  \n",
       "0    300.0    3945000.0      5000.0  13150.0  \n",
       "1    198.0    2524500.0       500.0  12750.0  \n",
       "2    138.0    4291800.0       500.0  31100.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.reset_index(drop = True, inplace=True)\n",
    "train_label.reset_index(drop = True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681472, 18)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681472,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_label.values.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681472, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_x, val_x, train_y, val_y = train_test_split(train_data, train_label, test_size=0.2, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_x.shape)\n",
    "# print(train_y.shape)\n",
    "# print(val_x.shape)\n",
    "# print(val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(16,input_shape=[18], activation='relu'),\n",
    "        layers.Dense(8,input_shape=[16], activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mae','accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                304       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 449\n",
      "Trainable params: 449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "17037/17037 [==============================] - 15s 818us/step - loss: 670853706524.2174 - mae: 53962.9019 - accuracy: 0.1544 - val_loss: 505692.2500 - val_mae: 146.5189 - val_accuracy: 0.2180\n",
      "Epoch 2/300\n",
      "17037/17037 [==============================] - 12s 701us/step - loss: 14255374180.2951 - mae: 7872.2646 - accuracy: 0.1614 - val_loss: 19372882.0000 - val_mae: 1801.4613 - val_accuracy: 0.2556\n",
      "Epoch 3/300\n",
      "17037/17037 [==============================] - 12s 728us/step - loss: 3216547525.7214 - mae: 6274.3349 - accuracy: 0.1332 - val_loss: 731192.0625 - val_mae: 477.5125 - val_accuracy: 0.0097\n",
      "Epoch 4/300\n",
      "17037/17037 [==============================] - 12s 696us/step - loss: 2330761463.5112 - mae: 4131.1704 - accuracy: 0.1117 - val_loss: 710.9485 - val_mae: 10.2366 - val_accuracy: 0.2726\n",
      "Epoch 5/300\n",
      "17037/17037 [==============================] - 15s 904us/step - loss: 492597.7022 - mae: 27.2248 - accuracy: 0.2798 - val_loss: 27010.5723 - val_mae: 100.8625 - val_accuracy: 0.2726\n",
      "Epoch 6/300\n",
      "17037/17037 [==============================] - 12s 717us/step - loss: 439948.5129 - mae: 25.3378 - accuracy: 0.2802 - val_loss: 409.2366 - val_mae: 12.9226 - val_accuracy: 0.2726\n",
      "Epoch 7/300\n",
      "17037/17037 [==============================] - 12s 675us/step - loss: 207003.9387 - mae: 24.3165 - accuracy: 0.2806 - val_loss: 354.7215 - val_mae: 13.1164 - val_accuracy: 0.2726\n",
      "Epoch 8/300\n",
      "17037/17037 [==============================] - 12s 676us/step - loss: 20214.0708 - mae: 20.2159 - accuracy: 0.2798 - val_loss: 487.1091 - val_mae: 12.0268 - val_accuracy: 0.2726\n",
      "Epoch 9/300\n",
      "17037/17037 [==============================] - 13s 762us/step - loss: 7612.1107 - mae: 17.6570 - accuracy: 0.2800 - val_loss: 554.2267 - val_mae: 9.8390 - val_accuracy: 0.2726\n",
      "Epoch 10/300\n",
      "17037/17037 [==============================] - 14s 820us/step - loss: 7425.7824 - mae: 16.1572 - accuracy: 0.2810 - val_loss: 29720.5938 - val_mae: 97.9531 - val_accuracy: 0.2726\n",
      "Epoch 11/300\n",
      "17037/17037 [==============================] - 14s 837us/step - loss: 4977.9599 - mae: 15.3784 - accuracy: 0.2798 - val_loss: 238.3566 - val_mae: 9.1180 - val_accuracy: 0.2726\n",
      "Epoch 12/300\n",
      "17037/17037 [==============================] - 12s 677us/step - loss: 4286.9985 - mae: 14.2187 - accuracy: 0.2804 - val_loss: 348.9753 - val_mae: 8.7627 - val_accuracy: 0.2726\n",
      "Epoch 13/300\n",
      "17037/17037 [==============================] - 11s 667us/step - loss: 6836.4733 - mae: 13.9428 - accuracy: 0.2810 - val_loss: 784.5213 - val_mae: 7.8386 - val_accuracy: 0.2726\n",
      "Epoch 14/300\n",
      "17037/17037 [==============================] - 13s 762us/step - loss: 10110.3106 - mae: 13.6086 - accuracy: 0.2797 - val_loss: 266.5229 - val_mae: 8.7361 - val_accuracy: 0.2726\n",
      "Epoch 15/300\n",
      "17037/17037 [==============================] - 17s 974us/step - loss: 4528.7785 - mae: 12.9006 - accuracy: 0.2812 - val_loss: 181.1927 - val_mae: 7.5374 - val_accuracy: 0.2726\n",
      "Epoch 16/300\n",
      "17037/17037 [==============================] - 12s 729us/step - loss: 5080.0745 - mae: 12.5756 - accuracy: 0.2808 - val_loss: 250.5880 - val_mae: 8.8080 - val_accuracy: 0.2726\n",
      "Epoch 17/300\n",
      "17037/17037 [==============================] - 12s 701us/step - loss: 3916.7398 - mae: 12.1977 - accuracy: 0.2812 - val_loss: 292.2986 - val_mae: 8.8048 - val_accuracy: 0.2726\n",
      "Epoch 18/300\n",
      "17037/17037 [==============================] - 11s 672us/step - loss: 3282.3071 - mae: 11.9868 - accuracy: 0.2801 - val_loss: 218.8385 - val_mae: 8.0529 - val_accuracy: 0.2726\n",
      "Epoch 19/300\n",
      "17037/17037 [==============================] - 13s 778us/step - loss: 2792.4669 - mae: 11.6461 - accuracy: 0.2808 - val_loss: 248.1681 - val_mae: 8.2754 - val_accuracy: 0.2726\n",
      "Epoch 20/300\n",
      "17037/17037 [==============================] - 12s 716us/step - loss: 3144.8578 - mae: 11.4747 - accuracy: 0.2800 - val_loss: 204.6849 - val_mae: 6.2523 - val_accuracy: 0.2726\n",
      "Epoch 21/300\n",
      "17037/17037 [==============================] - 15s 862us/step - loss: 3411.9822 - mae: 11.0010 - accuracy: 0.2799 - val_loss: 272.1264 - val_mae: 5.5350 - val_accuracy: 0.2726\n",
      "Epoch 22/300\n",
      "17037/17037 [==============================] - 13s 761us/step - loss: 1810.3266 - mae: 10.6470 - accuracy: 0.2806 - val_loss: 253.5242 - val_mae: 6.8937 - val_accuracy: 0.2726\n",
      "Epoch 23/300\n",
      "17037/17037 [==============================] - 14s 812us/step - loss: 4702.8707 - mae: 10.8518 - accuracy: 0.2798 - val_loss: 386.6797 - val_mae: 9.6043 - val_accuracy: 0.2726\n",
      "Epoch 24/300\n",
      "17037/17037 [==============================] - 14s 823us/step - loss: 3816.7672 - mae: 10.5871 - accuracy: 0.2817 - val_loss: 100.7523 - val_mae: 5.8953 - val_accuracy: 0.2726\n",
      "Epoch 25/300\n",
      "17037/17037 [==============================] - 16s 928us/step - loss: 2278.1484 - mae: 10.1910 - accuracy: 0.2806 - val_loss: 555.8082 - val_mae: 5.9779 - val_accuracy: 0.2726\n",
      "Epoch 26/300\n",
      "17037/17037 [==============================] - 17s 979us/step - loss: 3621.9163 - mae: 10.7173 - accuracy: 0.2807 - val_loss: 220.5708 - val_mae: 8.0247 - val_accuracy: 0.2726\n",
      "Epoch 27/300\n",
      "17037/17037 [==============================] - 14s 798us/step - loss: 2926.5501 - mae: 10.4523 - accuracy: 0.2802 - val_loss: 286.3853 - val_mae: 8.4542 - val_accuracy: 0.2726\n",
      "Epoch 28/300\n",
      "17037/17037 [==============================] - 17s 1ms/step - loss: 1700.2335 - mae: 9.7730 - accuracy: 0.2807 - val_loss: 232.3954 - val_mae: 7.3837 - val_accuracy: 0.2726\n",
      "Epoch 29/300\n",
      "17037/17037 [==============================] - 17s 987us/step - loss: 2095.2561 - mae: 9.8539 - accuracy: 0.2802 - val_loss: 146.7565 - val_mae: 6.4270 - val_accuracy: 0.2726\n",
      "Epoch 30/300\n",
      "17037/17037 [==============================] - 17s 970us/step - loss: 3932.5781 - mae: 10.5161 - accuracy: 0.2809 - val_loss: 181.2007 - val_mae: 6.5527 - val_accuracy: 0.2726\n",
      "Epoch 31/300\n",
      "17037/17037 [==============================] - 15s 852us/step - loss: 2858.9810 - mae: 10.5377 - accuracy: 0.2795 - val_loss: 450.1023 - val_mae: 6.3777 - val_accuracy: 0.2726\n",
      "Epoch 32/300\n",
      "17037/17037 [==============================] - 15s 853us/step - loss: 2978.0173 - mae: 10.6331 - accuracy: 0.2799 - val_loss: 159.8925 - val_mae: 6.9728 - val_accuracy: 0.2726\n",
      "Epoch 33/300\n",
      "17037/17037 [==============================] - 16s 931us/step - loss: 3650.6728 - mae: 10.5334 - accuracy: 0.2805 - val_loss: 106.1076 - val_mae: 5.5955 - val_accuracy: 0.2726\n",
      "Epoch 34/300\n",
      "17037/17037 [==============================] - 14s 817us/step - loss: 1724.6845 - mae: 9.9410 - accuracy: 0.2804 - val_loss: 389.2909 - val_mae: 11.8261 - val_accuracy: 0.2726\n",
      "Epoch 35/300\n",
      "17037/17037 [==============================] - 13s 765us/step - loss: 2269.0404 - mae: 10.0508 - accuracy: 0.2802 - val_loss: 169.7108 - val_mae: 5.4660 - val_accuracy: 0.2726\n",
      "Epoch 36/300\n",
      "17037/17037 [==============================] - 12s 691us/step - loss: 2288.9529 - mae: 9.8540 - accuracy: 0.2801 - val_loss: 17812.4746 - val_mae: 48.3827 - val_accuracy: 0.2726\n",
      "Epoch 37/300\n",
      "17037/17037 [==============================] - 15s 880us/step - loss: 2716.9955 - mae: 9.1407 - accuracy: 0.2808 - val_loss: 116.8210 - val_mae: 5.1372 - val_accuracy: 0.2726\n",
      "Epoch 38/300\n",
      "17037/17037 [==============================] - 14s 827us/step - loss: 1798.6947 - mae: 8.9560 - accuracy: 0.2795 - val_loss: 288.0699 - val_mae: 8.8313 - val_accuracy: 0.2726\n",
      "Epoch 39/300\n",
      "17037/17037 [==============================] - 17s 1ms/step - loss: 2722.6630 - mae: 8.6417 - accuracy: 0.2800 - val_loss: 146.0141 - val_mae: 6.3320 - val_accuracy: 0.2726\n",
      "Epoch 40/300\n",
      "17037/17037 [==============================] - 14s 809us/step - loss: 1617.8516 - mae: 9.0821 - accuracy: 0.2809 - val_loss: 142.0753 - val_mae: 5.7551 - val_accuracy: 0.2726\n",
      "Epoch 41/300\n",
      "17037/17037 [==============================] - 13s 781us/step - loss: 3570.4723 - mae: 9.2818 - accuracy: 0.2799 - val_loss: 354.7665 - val_mae: 9.1058 - val_accuracy: 0.2726\n",
      "Epoch 42/300\n",
      "17037/17037 [==============================] - 14s 824us/step - loss: 2557.7876 - mae: 8.6295 - accuracy: 0.2798 - val_loss: 93.7116 - val_mae: 3.9179 - val_accuracy: 0.2726\n",
      "Epoch 43/300\n",
      "17037/17037 [==============================] - 18s 1ms/step - loss: 1962.7759 - mae: 8.6696 - accuracy: 0.2810 - val_loss: 86.0235 - val_mae: 4.1747 - val_accuracy: 0.2726\n",
      "Epoch 44/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17037/17037 [==============================] - 16s 925us/step - loss: 4566.1003 - mae: 8.4613 - accuracy: 0.2802 - val_loss: 54.4163 - val_mae: 3.9404 - val_accuracy: 0.2726\n",
      "Epoch 45/300\n",
      "17037/17037 [==============================] - 15s 858us/step - loss: 8125.5065 - mae: 8.7477 - accuracy: 0.2806 - val_loss: 127.3555 - val_mae: 4.9260 - val_accuracy: 0.2726\n",
      "Epoch 46/300\n",
      "17037/17037 [==============================] - 14s 830us/step - loss: 1387.4067 - mae: 7.7763 - accuracy: 0.2803 - val_loss: 70.6388 - val_mae: 4.5965 - val_accuracy: 0.2726\n",
      "Epoch 47/300\n",
      "17037/17037 [==============================] - 15s 880us/step - loss: 1124.6008 - mae: 7.7796 - accuracy: 0.2803 - val_loss: 206.6014 - val_mae: 7.3359 - val_accuracy: 0.2726\n",
      "Epoch 48/300\n",
      "17037/17037 [==============================] - 15s 892us/step - loss: 2761.1843 - mae: 7.9623 - accuracy: 0.2798 - val_loss: 145.5305 - val_mae: 3.7759 - val_accuracy: 0.2726\n",
      "Epoch 49/300\n",
      "17037/17037 [==============================] - 15s 888us/step - loss: 1707.4785 - mae: 7.6359 - accuracy: 0.2799 - val_loss: 131.5841 - val_mae: 6.5031 - val_accuracy: 0.2726\n",
      "Epoch 50/300\n",
      "17037/17037 [==============================] - 14s 833us/step - loss: 5310.0631 - mae: 8.2680 - accuracy: 0.2808 - val_loss: 197.3089 - val_mae: 7.1427 - val_accuracy: 0.2726\n",
      "Epoch 51/300\n",
      "17037/17037 [==============================] - 15s 903us/step - loss: 994.2805 - mae: 7.4214 - accuracy: 0.2804 - val_loss: 67.8552 - val_mae: 4.0359 - val_accuracy: 0.2726\n",
      "Epoch 52/300\n",
      "17037/17037 [==============================] - 12s 688us/step - loss: 2849.2368 - mae: 7.2989 - accuracy: 0.2808 - val_loss: 74.2223 - val_mae: 3.7726 - val_accuracy: 0.2726\n",
      "Epoch 53/300\n",
      "17037/17037 [==============================] - 15s 878us/step - loss: 1650.6280 - mae: 7.3887 - accuracy: 0.2803 - val_loss: 83.9024 - val_mae: 4.4847 - val_accuracy: 0.2726\n",
      "Epoch 54/300\n",
      "17037/17037 [==============================] - 13s 767us/step - loss: 3786.9467 - mae: 7.3419 - accuracy: 0.2797 - val_loss: 115.0774 - val_mae: 4.8625 - val_accuracy: 0.2726\n",
      "Epoch 55/300\n",
      "17037/17037 [==============================] - 14s 824us/step - loss: 3685.8232 - mae: 7.4863 - accuracy: 0.2802 - val_loss: 42.8366 - val_mae: 3.8777 - val_accuracy: 0.2726\n",
      "Epoch 56/300\n",
      "17037/17037 [==============================] - 13s 741us/step - loss: 1258.3902 - mae: 7.3779 - accuracy: 0.2806 - val_loss: 46.8292 - val_mae: 3.8177 - val_accuracy: 0.2726\n",
      "Epoch 57/300\n",
      "17037/17037 [==============================] - 16s 913us/step - loss: 9787.8018 - mae: 7.1371 - accuracy: 0.2808 - val_loss: 197.1491 - val_mae: 5.0551 - val_accuracy: 0.2726\n",
      "Epoch 58/300\n",
      "17037/17037 [==============================] - 13s 770us/step - loss: 3913.1555 - mae: 7.4043 - accuracy: 0.2805 - val_loss: 175.2713 - val_mae: 5.6588 - val_accuracy: 0.2726\n",
      "Epoch 59/300\n",
      "17037/17037 [==============================] - 16s 917us/step - loss: 1040.4857 - mae: 7.2311 - accuracy: 0.2803 - val_loss: 80.0579 - val_mae: 4.7100 - val_accuracy: 0.2726\n",
      "Epoch 60/300\n",
      "17037/17037 [==============================] - 15s 853us/step - loss: 1603.4560 - mae: 7.3825 - accuracy: 0.2804 - val_loss: 125.1499 - val_mae: 4.8822 - val_accuracy: 0.2726\n",
      "Epoch 61/300\n",
      "17037/17037 [==============================] - 15s 889us/step - loss: 902.9213 - mae: 6.8573 - accuracy: 0.2805 - val_loss: 96.0321 - val_mae: 5.1104 - val_accuracy: 0.2726\n",
      "Epoch 62/300\n",
      "17037/17037 [==============================] - 17s 974us/step - loss: 1126.3354 - mae: 6.7600 - accuracy: 0.2801 - val_loss: 3782.8118 - val_mae: 26.4500 - val_accuracy: 0.2726\n",
      "Epoch 63/300\n",
      "17037/17037 [==============================] - 15s 858us/step - loss: 815.0601 - mae: 6.6119 - accuracy: 0.2802 - val_loss: 120.7848 - val_mae: 4.6671 - val_accuracy: 0.2726\n",
      "Epoch 64/300\n",
      "17037/17037 [==============================] - 17s 1ms/step - loss: 855.8189 - mae: 6.6156 - accuracy: 0.2807 - val_loss: 217.9383 - val_mae: 7.7452 - val_accuracy: 0.2726\n",
      "Epoch 65/300\n",
      "17037/17037 [==============================] - 13s 787us/step - loss: 1171.7115 - mae: 6.8260 - accuracy: 0.2809 - val_loss: 122.6273 - val_mae: 5.4299 - val_accuracy: 0.2726\n",
      "Epoch 66/300\n",
      "17037/17037 [==============================] - 15s 875us/step - loss: 785.8828 - mae: 6.4841 - accuracy: 0.2795 - val_loss: 90.7479 - val_mae: 4.2295 - val_accuracy: 0.2726\n",
      "Epoch 67/300\n",
      "17037/17037 [==============================] - 16s 911us/step - loss: 3964.5445 - mae: 6.4020 - accuracy: 0.2805 - val_loss: 68.5604 - val_mae: 3.6722 - val_accuracy: 0.2726\n",
      "Epoch 68/300\n",
      "17037/17037 [==============================] - 16s 935us/step - loss: 680.1416 - mae: 6.5733 - accuracy: 0.2802 - val_loss: 77.8634 - val_mae: 3.3015 - val_accuracy: 0.2726\n",
      "Epoch 69/300\n",
      "17037/17037 [==============================] - 16s 911us/step - loss: 2602.9812 - mae: 7.0749 - accuracy: 0.2796 - val_loss: 65.4362 - val_mae: 4.3243 - val_accuracy: 0.2726\n",
      "Epoch 70/300\n",
      "17037/17037 [==============================] - 16s 935us/step - loss: 1306.1824 - mae: 6.6012 - accuracy: 0.2791 - val_loss: 9.7862 - val_mae: 2.0712 - val_accuracy: 0.2726\n",
      "Epoch 71/300\n",
      "17037/17037 [==============================] - 16s 923us/step - loss: 898.4025 - mae: 6.3603 - accuracy: 0.2814 - val_loss: 56.6047 - val_mae: 3.5096 - val_accuracy: 0.2726\n",
      "Epoch 72/300\n",
      "17037/17037 [==============================] - 13s 789us/step - loss: 774.4237 - mae: 6.3426 - accuracy: 0.2805 - val_loss: 15.4728 - val_mae: 2.6247 - val_accuracy: 0.2726\n",
      "Epoch 73/300\n",
      "17037/17037 [==============================] - 15s 886us/step - loss: 1008.9204 - mae: 6.2895 - accuracy: 0.2799 - val_loss: 48.1698 - val_mae: 3.3442 - val_accuracy: 0.2726\n",
      "Epoch 74/300\n",
      "17037/17037 [==============================] - 14s 814us/step - loss: 714.7765 - mae: 6.5384 - accuracy: 0.2806 - val_loss: 37.1215 - val_mae: 2.9994 - val_accuracy: 0.2726\n",
      "Epoch 75/300\n",
      "17037/17037 [==============================] - 17s 1ms/step - loss: 789.6136 - mae: 6.3187 - accuracy: 0.2808 - val_loss: 78.9283 - val_mae: 4.4845 - val_accuracy: 0.2726\n",
      "Epoch 76/300\n",
      "17037/17037 [==============================] - 14s 823us/step - loss: 1328.8775 - mae: 6.1491 - accuracy: 0.2802 - val_loss: 47.2387 - val_mae: 4.0359 - val_accuracy: 0.2726\n",
      "Epoch 77/300\n",
      "17037/17037 [==============================] - 16s 920us/step - loss: 741.1301 - mae: 6.0765 - accuracy: 0.2807 - val_loss: 178.5886 - val_mae: 6.9682 - val_accuracy: 0.2726\n",
      "Epoch 78/300\n",
      "17037/17037 [==============================] - 16s 925us/step - loss: 862.6963 - mae: 6.0325 - accuracy: 0.2803 - val_loss: 85.4538 - val_mae: 5.3364 - val_accuracy: 0.2726\n",
      "Epoch 79/300\n",
      "17037/17037 [==============================] - 13s 755us/step - loss: 889.2434 - mae: 5.9228 - accuracy: 0.2791 - val_loss: 23.3448 - val_mae: 3.0586 - val_accuracy: 0.2726\n",
      "Epoch 80/300\n",
      "17037/17037 [==============================] - 15s 865us/step - loss: 563.2407 - mae: 5.8575 - accuracy: 0.2807 - val_loss: 26.9146 - val_mae: 3.1939 - val_accuracy: 0.2726\n",
      "Epoch 81/300\n",
      "17037/17037 [==============================] - 15s 905us/step - loss: 444.1884 - mae: 5.4978 - accuracy: 0.2808 - val_loss: 138.1137 - val_mae: 6.2700 - val_accuracy: 0.2726\n",
      "Epoch 82/300\n",
      "17037/17037 [==============================] - 12s 732us/step - loss: 435.8979 - mae: 5.8277 - accuracy: 0.2803 - val_loss: 39.6486 - val_mae: 3.4127 - val_accuracy: 0.2726\n",
      "Epoch 83/300\n",
      "17037/17037 [==============================] - 16s 930us/step - loss: 638.6195 - mae: 5.6840 - accuracy: 0.2809 - val_loss: 177.0416 - val_mae: 7.0651 - val_accuracy: 0.2726\n",
      "Epoch 84/300\n",
      "17037/17037 [==============================] - 15s 867us/step - loss: 561.4992 - mae: 5.8484 - accuracy: 0.2804 - val_loss: 28.1474 - val_mae: 3.0606 - val_accuracy: 0.2726\n",
      "Epoch 85/300\n",
      "17037/17037 [==============================] - 16s 930us/step - loss: 522.3298 - mae: 5.4639 - accuracy: 0.2806 - val_loss: 30.3088 - val_mae: 2.8641 - val_accuracy: 0.2726\n",
      "Epoch 86/300\n",
      "17037/17037 [==============================] - 14s 814us/step - loss: 657.6529 - mae: 5.9181 - accuracy: 0.2795 - val_loss: 93.2579 - val_mae: 4.7670 - val_accuracy: 0.2726\n",
      "Epoch 87/300\n",
      "17037/17037 [==============================] - 13s 760us/step - loss: 1008.7787 - mae: 5.9456 - accuracy: 0.2809 - val_loss: 39.4271 - val_mae: 3.5310 - val_accuracy: 0.2726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/300\n",
      "17037/17037 [==============================] - 13s 786us/step - loss: 1294.2232 - mae: 6.0225 - accuracy: 0.2806 - val_loss: 9.6635 - val_mae: 2.3223 - val_accuracy: 0.2726\n",
      "Epoch 89/300\n",
      "17037/17037 [==============================] - 13s 750us/step - loss: 421.7166 - mae: 5.2539 - accuracy: 0.2807 - val_loss: 23.4608 - val_mae: 2.5845 - val_accuracy: 0.2726\n",
      "Epoch 90/300\n",
      "17037/17037 [==============================] - 13s 736us/step - loss: 2866.7457 - mae: 5.6953 - accuracy: 0.2801 - val_loss: 288.0898 - val_mae: 8.5592 - val_accuracy: 0.2726\n",
      "Epoch 91/300\n",
      "17037/17037 [==============================] - 16s 924us/step - loss: 509.7525 - mae: 5.2165 - accuracy: 0.2802 - val_loss: 15.0195 - val_mae: 2.3273 - val_accuracy: 0.2726\n",
      "Epoch 92/300\n",
      "17037/17037 [==============================] - 15s 853us/step - loss: 528.5114 - mae: 5.5725 - accuracy: 0.2802 - val_loss: 52.4752 - val_mae: 4.5069 - val_accuracy: 0.2726\n",
      "Epoch 93/300\n",
      "17037/17037 [==============================] - 16s 964us/step - loss: 360.7782 - mae: 5.3642 - accuracy: 0.2808 - val_loss: 63.9404 - val_mae: 3.8402 - val_accuracy: 0.2726\n",
      "Epoch 94/300\n",
      "17037/17037 [==============================] - 16s 929us/step - loss: 681.8123 - mae: 5.5831 - accuracy: 0.2800 - val_loss: 73.0640 - val_mae: 4.1998 - val_accuracy: 0.2726\n",
      "Epoch 95/300\n",
      "17037/17037 [==============================] - 16s 960us/step - loss: 363.4525 - mae: 5.0982 - accuracy: 0.2798 - val_loss: 11.3946 - val_mae: 1.8564 - val_accuracy: 0.2726\n",
      "Epoch 96/300\n",
      "17037/17037 [==============================] - 16s 960us/step - loss: 550.7947 - mae: 5.0542 - accuracy: 0.2795 - val_loss: 30.5768 - val_mae: 2.9145 - val_accuracy: 0.2726\n",
      "Epoch 97/300\n",
      "17037/17037 [==============================] - 14s 828us/step - loss: 382.2677 - mae: 5.2919 - accuracy: 0.2808 - val_loss: 85.5700 - val_mae: 4.4372 - val_accuracy: 0.2726\n",
      "Epoch 98/300\n",
      "17037/17037 [==============================] - 14s 811us/step - loss: 410.5150 - mae: 5.2939 - accuracy: 0.2809 - val_loss: 8.5780 - val_mae: 2.0540 - val_accuracy: 0.2726\n",
      "Epoch 99/300\n",
      "17037/17037 [==============================] - 12s 732us/step - loss: 505.6178 - mae: 5.0390 - accuracy: 0.2804 - val_loss: 39.6197 - val_mae: 4.8258 - val_accuracy: 0.2726\n",
      "Epoch 100/300\n",
      "17037/17037 [==============================] - 11s 660us/step - loss: 280.2785 - mae: 4.6609 - accuracy: 0.2813 - val_loss: 793.7755 - val_mae: 10.0167 - val_accuracy: 0.2726\n",
      "Epoch 101/300\n",
      "17037/17037 [==============================] - 12s 683us/step - loss: 512.1200 - mae: 5.2358 - accuracy: 0.2798 - val_loss: 60.0128 - val_mae: 4.6951 - val_accuracy: 0.2726\n",
      "Epoch 102/300\n",
      "17037/17037 [==============================] - 11s 627us/step - loss: 367.4646 - mae: 5.0092 - accuracy: 0.2804 - val_loss: 15.4451 - val_mae: 2.3803 - val_accuracy: 0.2726\n",
      "Epoch 103/300\n",
      "17037/17037 [==============================] - 13s 740us/step - loss: 363.1988 - mae: 4.8433 - accuracy: 0.2796 - val_loss: 76.2484 - val_mae: 4.1072 - val_accuracy: 0.2726\n",
      "Epoch 104/300\n",
      "17037/17037 [==============================] - 11s 656us/step - loss: 406.1368 - mae: 4.9455 - accuracy: 0.2804 - val_loss: 8.5199 - val_mae: 1.7712 - val_accuracy: 0.2726\n",
      "Epoch 105/300\n",
      "17037/17037 [==============================] - 12s 731us/step - loss: 500.9945 - mae: 4.8163 - accuracy: 0.2795 - val_loss: 56.7624 - val_mae: 3.5542 - val_accuracy: 0.2726\n",
      "Epoch 106/300\n",
      "17037/17037 [==============================] - 16s 954us/step - loss: 752.8672 - mae: 4.9935 - accuracy: 0.2802 - val_loss: 92.8176 - val_mae: 4.3574 - val_accuracy: 0.2726\n",
      "Epoch 107/300\n",
      "17037/17037 [==============================] - 11s 665us/step - loss: 498.7976 - mae: 4.9282 - accuracy: 0.2803 - val_loss: 59.9839 - val_mae: 4.1314 - val_accuracy: 0.2726\n",
      "Epoch 108/300\n",
      "17037/17037 [==============================] - 12s 685us/step - loss: 311.6881 - mae: 4.7196 - accuracy: 0.2801 - val_loss: 14.5104 - val_mae: 2.2001 - val_accuracy: 0.2726\n",
      "Epoch 109/300\n",
      "17037/17037 [==============================] - 11s 667us/step - loss: 296.1446 - mae: 4.8258 - accuracy: 0.2792 - val_loss: 38.8784 - val_mae: 2.7237 - val_accuracy: 0.2726\n",
      "Epoch 110/300\n",
      "17037/17037 [==============================] - 12s 694us/step - loss: 359.6923 - mae: 4.8979 - accuracy: 0.2802 - val_loss: 72.1106 - val_mae: 4.0899 - val_accuracy: 0.2726\n",
      "Epoch 111/300\n",
      "17037/17037 [==============================] - 11s 618us/step - loss: 430.1903 - mae: 4.6565 - accuracy: 0.2806 - val_loss: 12.9786 - val_mae: 1.6780 - val_accuracy: 0.2726\n",
      "Epoch 112/300\n",
      "17037/17037 [==============================] - 11s 666us/step - loss: 276.3673 - mae: 4.8180 - accuracy: 0.2800 - val_loss: 56.6475 - val_mae: 3.5562 - val_accuracy: 0.2726\n",
      "Epoch 113/300\n",
      "17037/17037 [==============================] - 11s 634us/step - loss: 280.4766 - mae: 4.5505 - accuracy: 0.2798 - val_loss: 59.5683 - val_mae: 3.8059 - val_accuracy: 0.2726\n",
      "Epoch 114/300\n",
      "17037/17037 [==============================] - 12s 702us/step - loss: 1403.0898 - mae: 4.5027 - accuracy: 0.2801 - val_loss: 18.8006 - val_mae: 2.5509 - val_accuracy: 0.2726\n",
      "Epoch 115/300\n",
      "17037/17037 [==============================] - 11s 642us/step - loss: 558.7232 - mae: 4.6395 - accuracy: 0.2800 - val_loss: 35.3827 - val_mae: 3.1556 - val_accuracy: 0.2726\n",
      "Epoch 116/300\n",
      "17037/17037 [==============================] - 12s 732us/step - loss: 233.3207 - mae: 4.5182 - accuracy: 0.2803 - val_loss: 11.5823 - val_mae: 1.6043 - val_accuracy: 0.2726\n",
      "Epoch 117/300\n",
      "17037/17037 [==============================] - 13s 761us/step - loss: 457.0226 - mae: 4.3413 - accuracy: 0.2805 - val_loss: 81.8168 - val_mae: 4.9014 - val_accuracy: 0.2726\n",
      "Epoch 118/300\n",
      "17037/17037 [==============================] - 14s 832us/step - loss: 241.7827 - mae: 4.2710 - accuracy: 0.2810 - val_loss: 32.4874 - val_mae: 2.7629 - val_accuracy: 0.2726\n",
      "Epoch 119/300\n",
      "17037/17037 [==============================] - 14s 825us/step - loss: 336.7479 - mae: 4.4230 - accuracy: 0.2804 - val_loss: 77.6147 - val_mae: 4.4561 - val_accuracy: 0.2726\n",
      "Epoch 120/300\n",
      "17037/17037 [==============================] - 12s 731us/step - loss: 299.6795 - mae: 4.4387 - accuracy: 0.2811 - val_loss: 63.5084 - val_mae: 3.6369 - val_accuracy: 0.2726\n",
      "Epoch 121/300\n",
      "17037/17037 [==============================] - 14s 825us/step - loss: 329.0892 - mae: 4.4932 - accuracy: 0.2801 - val_loss: 120.2239 - val_mae: 5.8404 - val_accuracy: 0.2726\n",
      "Epoch 122/300\n",
      "17037/17037 [==============================] - 15s 905us/step - loss: 357.3919 - mae: 4.6099 - accuracy: 0.2806 - val_loss: 66.3301 - val_mae: 3.9348 - val_accuracy: 0.2726\n",
      "Epoch 123/300\n",
      "17037/17037 [==============================] - 17s 991us/step - loss: 296.8471 - mae: 4.3180 - accuracy: 0.2798 - val_loss: 66.3115 - val_mae: 4.0338 - val_accuracy: 0.2726\n",
      "Epoch 124/300\n",
      "17037/17037 [==============================] - 12s 677us/step - loss: 340.9844 - mae: 4.4930 - accuracy: 0.2797 - val_loss: 9.9579 - val_mae: 1.8584 - val_accuracy: 0.2726\n",
      "Epoch 125/300\n",
      "17037/17037 [==============================] - 14s 828us/step - loss: 345.2378 - mae: 4.3264 - accuracy: 0.2802 - val_loss: 51.9063 - val_mae: 3.4124 - val_accuracy: 0.2726\n",
      "Epoch 126/300\n",
      "17037/17037 [==============================] - 13s 760us/step - loss: 431.9241 - mae: 4.1840 - accuracy: 0.2803 - val_loss: 57.2195 - val_mae: 3.5151 - val_accuracy: 0.2726\n",
      "Epoch 127/300\n",
      "17037/17037 [==============================] - 15s 870us/step - loss: 321.0743 - mae: 4.2377 - accuracy: 0.2809 - val_loss: 60.5779 - val_mae: 3.8258 - val_accuracy: 0.2726\n",
      "Epoch 128/300\n",
      "17037/17037 [==============================] - 15s 872us/step - loss: 288.7949 - mae: 4.2755 - accuracy: 0.2802 - val_loss: 93.4267 - val_mae: 4.6741 - val_accuracy: 0.2726\n",
      "Epoch 129/300\n",
      "17037/17037 [==============================] - 13s 743us/step - loss: 326.8553 - mae: 4.3295 - accuracy: 0.2803 - val_loss: 7.8982 - val_mae: 1.7719 - val_accuracy: 0.2726\n",
      "Epoch 130/300\n",
      "17037/17037 [==============================] - 12s 680us/step - loss: 246.5407 - mae: 4.1383 - accuracy: 0.2803 - val_loss: 13.0753 - val_mae: 1.9968 - val_accuracy: 0.2726\n",
      "Epoch 131/300\n",
      "17037/17037 [==============================] - 11s 653us/step - loss: 631.1992 - mae: 4.2914 - accuracy: 0.2808 - val_loss: 75.5142 - val_mae: 4.9219 - val_accuracy: 0.2726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/300\n",
      "17037/17037 [==============================] - 15s 883us/step - loss: 360.8944 - mae: 4.2473 - accuracy: 0.2811 - val_loss: 33.8303 - val_mae: 3.0359 - val_accuracy: 0.2726\n",
      "Epoch 133/300\n",
      "17037/17037 [==============================] - 13s 771us/step - loss: 335.9479 - mae: 4.0972 - accuracy: 0.2807 - val_loss: 4.3939 - val_mae: 1.2536 - val_accuracy: 0.2726\n",
      "Epoch 134/300\n",
      "17037/17037 [==============================] - 15s 877us/step - loss: 296.4145 - mae: 4.1442 - accuracy: 0.2803 - val_loss: 8.3710 - val_mae: 1.9215 - val_accuracy: 0.2726\n",
      "Epoch 135/300\n",
      "17037/17037 [==============================] - 11s 622us/step - loss: 260.0613 - mae: 4.2994 - accuracy: 0.2799 - val_loss: 36.9361 - val_mae: 2.9965 - val_accuracy: 0.2726\n",
      "Epoch 136/300\n",
      "17037/17037 [==============================] - 14s 848us/step - loss: 1030.8251 - mae: 4.1851 - accuracy: 0.2803 - val_loss: 58.9560 - val_mae: 3.6581 - val_accuracy: 0.2726\n",
      "Epoch 137/300\n",
      "17037/17037 [==============================] - 14s 804us/step - loss: 434.7804 - mae: 4.1708 - accuracy: 0.2789 - val_loss: 12.8567 - val_mae: 1.6094 - val_accuracy: 0.2726\n",
      "Epoch 138/300\n",
      "17037/17037 [==============================] - 14s 836us/step - loss: 265.5295 - mae: 3.9537 - accuracy: 0.2811 - val_loss: 25.7674 - val_mae: 3.1885 - val_accuracy: 0.2726\n",
      "Epoch 139/300\n",
      "17037/17037 [==============================] - 15s 852us/step - loss: 263.1075 - mae: 4.0734 - accuracy: 0.2802 - val_loss: 9.9289 - val_mae: 2.0767 - val_accuracy: 0.2726\n",
      "Epoch 140/300\n",
      "17037/17037 [==============================] - 14s 820us/step - loss: 458.8021 - mae: 4.2105 - accuracy: 0.2796 - val_loss: 9.0325 - val_mae: 1.4367 - val_accuracy: 0.2726\n",
      "Epoch 141/300\n",
      "17037/17037 [==============================] - 13s 761us/step - loss: 229.2917 - mae: 3.9153 - accuracy: 0.2806 - val_loss: 5.3650 - val_mae: 1.3425 - val_accuracy: 0.2726\n",
      "Epoch 142/300\n",
      "17037/17037 [==============================] - 13s 777us/step - loss: 223.8037 - mae: 3.9900 - accuracy: 0.2802 - val_loss: 8.1706 - val_mae: 1.4883 - val_accuracy: 0.2726\n",
      "Epoch 143/300\n",
      "17037/17037 [==============================] - 13s 776us/step - loss: 263.0192 - mae: 4.0345 - accuracy: 0.2801 - val_loss: 1932.8545 - val_mae: 17.0954 - val_accuracy: 0.2726\n",
      "Epoch 144/300\n",
      "17037/17037 [==============================] - 14s 804us/step - loss: 388.2457 - mae: 4.0665 - accuracy: 0.2794 - val_loss: 116.5760 - val_mae: 5.6293 - val_accuracy: 0.2726\n",
      "Epoch 145/300\n",
      "17037/17037 [==============================] - 14s 807us/step - loss: 215.9008 - mae: 4.0380 - accuracy: 0.2811 - val_loss: 588.6711 - val_mae: 7.4409 - val_accuracy: 0.2726\n",
      "Epoch 146/300\n",
      "17037/17037 [==============================] - 12s 716us/step - loss: 215.3584 - mae: 3.9236 - accuracy: 0.2814 - val_loss: 27.2608 - val_mae: 2.4625 - val_accuracy: 0.2726\n",
      "Epoch 147/300\n",
      "17037/17037 [==============================] - 14s 843us/step - loss: 479.9521 - mae: 3.9816 - accuracy: 0.2801 - val_loss: 5.8806 - val_mae: 1.3673 - val_accuracy: 0.2726\n",
      "Epoch 148/300\n",
      "17037/17037 [==============================] - 13s 761us/step - loss: 276.9328 - mae: 4.0440 - accuracy: 0.2807 - val_loss: 88.8315 - val_mae: 4.4101 - val_accuracy: 0.2726\n",
      "Epoch 149/300\n",
      "17037/17037 [==============================] - 16s 938us/step - loss: 316.9481 - mae: 3.8986 - accuracy: 0.2803 - val_loss: 44.4858 - val_mae: 4.0376 - val_accuracy: 0.2726\n",
      "Epoch 150/300\n",
      "17037/17037 [==============================] - 18s 1ms/step - loss: 281.6145 - mae: 4.0177 - accuracy: 0.2814 - val_loss: 32.5539 - val_mae: 2.7539 - val_accuracy: 0.2726\n",
      "Epoch 151/300\n",
      "17037/17037 [==============================] - 11s 660us/step - loss: 231.2576 - mae: 3.9030 - accuracy: 0.2805 - val_loss: 53.3873 - val_mae: 3.5719 - val_accuracy: 0.2726\n",
      "Epoch 152/300\n",
      "17037/17037 [==============================] - 15s 895us/step - loss: 219.9142 - mae: 3.9607 - accuracy: 0.2800 - val_loss: 20.6787 - val_mae: 2.1882 - val_accuracy: 0.2726\n",
      "Epoch 153/300\n",
      "17037/17037 [==============================] - 13s 774us/step - loss: 184.5181 - mae: 3.9338 - accuracy: 0.2795 - val_loss: 26.1782 - val_mae: 2.2640 - val_accuracy: 0.2726\n",
      "Epoch 154/300\n",
      "17037/17037 [==============================] - 11s 662us/step - loss: 289.2779 - mae: 3.8337 - accuracy: 0.2808 - val_loss: 3.8514 - val_mae: 1.2387 - val_accuracy: 0.2726\n",
      "Epoch 155/300\n",
      "17037/17037 [==============================] - 15s 886us/step - loss: 263.1687 - mae: 3.8352 - accuracy: 0.2810 - val_loss: 33.3614 - val_mae: 2.2756 - val_accuracy: 0.2726\n",
      "Epoch 156/300\n",
      "17037/17037 [==============================] - 13s 761us/step - loss: 862.6547 - mae: 3.9659 - accuracy: 0.2802 - val_loss: 58.4066 - val_mae: 3.4625 - val_accuracy: 0.2726\n",
      "Epoch 157/300\n",
      "17037/17037 [==============================] - 15s 852us/step - loss: 195.8579 - mae: 3.8319 - accuracy: 0.2801 - val_loss: 95.9557 - val_mae: 4.8931 - val_accuracy: 0.2726\n",
      "Epoch 158/300\n",
      "17037/17037 [==============================] - 16s 957us/step - loss: 229.0859 - mae: 3.7893 - accuracy: 0.2809 - val_loss: 15.6492 - val_mae: 1.8994 - val_accuracy: 0.2726\n",
      "Epoch 159/300\n",
      "17037/17037 [==============================] - 15s 859us/step - loss: 252.0741 - mae: 3.6985 - accuracy: 0.2803 - val_loss: 31.3471 - val_mae: 2.5159 - val_accuracy: 0.2726\n",
      "Epoch 160/300\n",
      "17037/17037 [==============================] - 14s 826us/step - loss: 253.4937 - mae: 3.6983 - accuracy: 0.2808 - val_loss: 14.9894 - val_mae: 1.8033 - val_accuracy: 0.2726\n",
      "Epoch 161/300\n",
      "17037/17037 [==============================] - 13s 783us/step - loss: 240.6309 - mae: 3.6365 - accuracy: 0.2803 - val_loss: 55.9276 - val_mae: 4.1739 - val_accuracy: 0.2726\n",
      "Epoch 162/300\n",
      "17037/17037 [==============================] - 15s 891us/step - loss: 174.7440 - mae: 3.6335 - accuracy: 0.2809 - val_loss: 7.5035 - val_mae: 1.5393 - val_accuracy: 0.2726\n",
      "Epoch 163/300\n",
      "17037/17037 [==============================] - 16s 916us/step - loss: 281.0841 - mae: 3.5085 - accuracy: 0.2803 - val_loss: 9.4271 - val_mae: 1.7219 - val_accuracy: 0.2726\n",
      "Epoch 164/300\n",
      "17037/17037 [==============================] - 12s 717us/step - loss: 268.5775 - mae: 3.5987 - accuracy: 0.2811 - val_loss: 5.0945 - val_mae: 1.2388 - val_accuracy: 0.2726\n",
      "Epoch 165/300\n",
      "17037/17037 [==============================] - 14s 805us/step - loss: 263.5704 - mae: 3.5349 - accuracy: 0.2809 - val_loss: 30.0760 - val_mae: 2.9628 - val_accuracy: 0.2726\n",
      "Epoch 166/300\n",
      "17037/17037 [==============================] - 13s 778us/step - loss: 287.0011 - mae: 3.6280 - accuracy: 0.2809 - val_loss: 19.5899 - val_mae: 2.6346 - val_accuracy: 0.2726\n",
      "Epoch 167/300\n",
      "17037/17037 [==============================] - 13s 764us/step - loss: 156.3444 - mae: 3.4265 - accuracy: 0.2805 - val_loss: 25.1763 - val_mae: 2.2806 - val_accuracy: 0.2726\n",
      "Epoch 168/300\n",
      "17037/17037 [==============================] - 12s 679us/step - loss: 241.1313 - mae: 3.6204 - accuracy: 0.2807 - val_loss: 38.1020 - val_mae: 3.3613 - val_accuracy: 0.2726\n",
      "Epoch 169/300\n",
      "17037/17037 [==============================] - 13s 757us/step - loss: 211.3410 - mae: 3.4359 - accuracy: 0.2817 - val_loss: 34.9235 - val_mae: 3.4363 - val_accuracy: 0.2726\n",
      "Epoch 170/300\n",
      "17037/17037 [==============================] - 13s 734us/step - loss: 171.4850 - mae: 3.4326 - accuracy: 0.2802 - val_loss: 41.7915 - val_mae: 2.8151 - val_accuracy: 0.2726\n",
      "Epoch 171/300\n",
      "17037/17037 [==============================] - 13s 789us/step - loss: 163.6978 - mae: 3.4004 - accuracy: 0.2808 - val_loss: 10.6650 - val_mae: 1.4007 - val_accuracy: 0.2726\n",
      "Epoch 172/300\n",
      "17037/17037 [==============================] - 15s 863us/step - loss: 255.6888 - mae: 3.3536 - accuracy: 0.2809 - val_loss: 49.7500 - val_mae: 3.1993 - val_accuracy: 0.2726\n",
      "Epoch 173/300\n",
      "17037/17037 [==============================] - 16s 941us/step - loss: 169.0132 - mae: 3.3014 - accuracy: 0.2804 - val_loss: 10.6730 - val_mae: 1.7593 - val_accuracy: 0.2726\n",
      "Epoch 174/300\n",
      "17037/17037 [==============================] - 14s 807us/step - loss: 236.8565 - mae: 3.3036 - accuracy: 0.2801 - val_loss: 25.6581 - val_mae: 2.6915 - val_accuracy: 0.2726\n",
      "Epoch 175/300\n",
      "17037/17037 [==============================] - 12s 716us/step - loss: 146.8690 - mae: 3.3141 - accuracy: 0.2799 - val_loss: 14.2135 - val_mae: 1.7162 - val_accuracy: 0.2726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/300\n",
      "17037/17037 [==============================] - 14s 819us/step - loss: 192.7649 - mae: 3.4043 - accuracy: 0.2809 - val_loss: 2.7825 - val_mae: 0.8655 - val_accuracy: 0.2726\n",
      "Epoch 177/300\n",
      "17037/17037 [==============================] - 9s 501us/step - loss: 191.2357 - mae: 3.3285 - accuracy: 0.2793 - val_loss: 9.6655 - val_mae: 1.2994 - val_accuracy: 0.2726\n",
      "Epoch 178/300\n",
      "17037/17037 [==============================] - 8s 470us/step - loss: 274.2740 - mae: 3.3160 - accuracy: 0.2812 - val_loss: 28.6500 - val_mae: 3.2618 - val_accuracy: 0.2726\n",
      "Epoch 179/300\n",
      "17037/17037 [==============================] - 8s 457us/step - loss: 404.8595 - mae: 3.3503 - accuracy: 0.2796 - val_loss: 28.1053 - val_mae: 2.3115 - val_accuracy: 0.2726\n",
      "Epoch 180/300\n",
      "17037/17037 [==============================] - 8s 484us/step - loss: 152.8203 - mae: 3.2618 - accuracy: 0.2798 - val_loss: 51.9575 - val_mae: 3.6792 - val_accuracy: 0.2726\n",
      "Epoch 181/300\n",
      "17037/17037 [==============================] - 8s 462us/step - loss: 170.5825 - mae: 3.2624 - accuracy: 0.2795 - val_loss: 9.8213 - val_mae: 1.3280 - val_accuracy: 0.2726\n",
      "Epoch 182/300\n",
      "17037/17037 [==============================] - 9s 519us/step - loss: 750.1154 - mae: 3.3454 - accuracy: 0.2809 - val_loss: 67.0034 - val_mae: 3.1298 - val_accuracy: 0.2726\n",
      "Epoch 183/300\n",
      "17037/17037 [==============================] - 11s 653us/step - loss: 250.9759 - mae: 3.3484 - accuracy: 0.2811 - val_loss: 11.9931 - val_mae: 1.7154 - val_accuracy: 0.2726\n",
      "Epoch 184/300\n",
      "17037/17037 [==============================] - 11s 636us/step - loss: 197.4512 - mae: 3.2135 - accuracy: 0.2805 - val_loss: 19.7759 - val_mae: 2.3712 - val_accuracy: 0.2726\n",
      "Epoch 185/300\n",
      "17037/17037 [==============================] - 11s 624us/step - loss: 162.8881 - mae: 3.2430 - accuracy: 0.2814 - val_loss: 3.3105 - val_mae: 0.9600 - val_accuracy: 0.2726\n",
      "Epoch 186/300\n",
      "17037/17037 [==============================] - 10s 569us/step - loss: 143.5858 - mae: 3.1907 - accuracy: 0.2796 - val_loss: 10.1183 - val_mae: 1.5468 - val_accuracy: 0.2726\n",
      "Epoch 187/300\n",
      "17037/17037 [==============================] - 10s 588us/step - loss: 150.1319 - mae: 3.2194 - accuracy: 0.2815 - val_loss: 14.2198 - val_mae: 1.7023 - val_accuracy: 0.2726\n",
      "Epoch 188/300\n",
      "17037/17037 [==============================] - 10s 604us/step - loss: 169.8212 - mae: 3.2043 - accuracy: 0.2797 - val_loss: 28.9773 - val_mae: 2.4506 - val_accuracy: 0.2726\n",
      "Epoch 189/300\n",
      "17037/17037 [==============================] - 10s 599us/step - loss: 241.5561 - mae: 3.2496 - accuracy: 0.2797 - val_loss: 8.0154 - val_mae: 1.5054 - val_accuracy: 0.2726\n",
      "Epoch 190/300\n",
      "17037/17037 [==============================] - 11s 622us/step - loss: 177.9841 - mae: 3.1745 - accuracy: 0.2805 - val_loss: 14.3266 - val_mae: 2.0860 - val_accuracy: 0.2726\n",
      "Epoch 191/300\n",
      "17037/17037 [==============================] - 10s 578us/step - loss: 143.5513 - mae: 3.0817 - accuracy: 0.2806 - val_loss: 27.6807 - val_mae: 2.6147 - val_accuracy: 0.2726\n",
      "Epoch 192/300\n",
      "17037/17037 [==============================] - 9s 557us/step - loss: 201.0937 - mae: 3.2454 - accuracy: 0.2809 - val_loss: 28.1335 - val_mae: 2.4098 - val_accuracy: 0.2726\n",
      "Epoch 193/300\n",
      "17037/17037 [==============================] - 10s 606us/step - loss: 206.2072 - mae: 3.3079 - accuracy: 0.2806 - val_loss: 5.8331 - val_mae: 1.1470 - val_accuracy: 0.2726\n",
      "Epoch 194/300\n",
      "17037/17037 [==============================] - 11s 642us/step - loss: 152.5512 - mae: 3.1817 - accuracy: 0.2806 - val_loss: 27.9796 - val_mae: 2.2245 - val_accuracy: 0.2726\n",
      "Epoch 195/300\n",
      "17037/17037 [==============================] - 9s 511us/step - loss: 142.9280 - mae: 3.1890 - accuracy: 0.2811 - val_loss: 24.7091 - val_mae: 2.6751 - val_accuracy: 0.2726\n",
      "Epoch 196/300\n",
      "17037/17037 [==============================] - 8s 476us/step - loss: 575.9531 - mae: 3.2554 - accuracy: 0.2795 - val_loss: 5.9598 - val_mae: 1.3458 - val_accuracy: 0.2726\n",
      "Epoch 197/300\n",
      "17037/17037 [==============================] - 8s 475us/step - loss: 260.3770 - mae: 3.1603 - accuracy: 0.2800 - val_loss: 6.4615 - val_mae: 1.5263 - val_accuracy: 0.2726\n",
      "Epoch 198/300\n",
      "17037/17037 [==============================] - 8s 473us/step - loss: 176.2135 - mae: 3.1410 - accuracy: 0.2798 - val_loss: 6.1501 - val_mae: 1.1930 - val_accuracy: 0.2726\n",
      "Epoch 199/300\n",
      "17037/17037 [==============================] - 8s 475us/step - loss: 191.9748 - mae: 3.1461 - accuracy: 0.2800 - val_loss: 4.1324 - val_mae: 1.0455 - val_accuracy: 0.2726\n",
      "Epoch 200/300\n",
      "17037/17037 [==============================] - 8s 486us/step - loss: 159.6160 - mae: 3.1107 - accuracy: 0.2803 - val_loss: 4.1372 - val_mae: 0.9126 - val_accuracy: 0.2726\n",
      "Epoch 201/300\n",
      "17037/17037 [==============================] - 8s 473us/step - loss: 209.7759 - mae: 3.3220 - accuracy: 0.2809 - val_loss: 14.8244 - val_mae: 1.6860 - val_accuracy: 0.2726\n",
      "Epoch 202/300\n",
      "17037/17037 [==============================] - 8s 478us/step - loss: 694.3636 - mae: 3.0267 - accuracy: 0.2809 - val_loss: 4.9757 - val_mae: 1.1086 - val_accuracy: 0.2726\n",
      "Epoch 203/300\n",
      "17037/17037 [==============================] - 8s 494us/step - loss: 158.3611 - mae: 3.0541 - accuracy: 0.2810 - val_loss: 92.3564 - val_mae: 5.1265 - val_accuracy: 0.2726\n",
      "Epoch 204/300\n",
      "17037/17037 [==============================] - 8s 481us/step - loss: 130.8451 - mae: 3.0939 - accuracy: 0.2815 - val_loss: 6.7908 - val_mae: 1.2518 - val_accuracy: 0.2726\n",
      "Epoch 205/300\n",
      "17037/17037 [==============================] - 8s 491us/step - loss: 124.2987 - mae: 3.0188 - accuracy: 0.2809 - val_loss: 12.0806 - val_mae: 1.5984 - val_accuracy: 0.2726\n",
      "Epoch 206/300\n",
      "17037/17037 [==============================] - 9s 507us/step - loss: 183.3636 - mae: 3.1320 - accuracy: 0.2802 - val_loss: 14.7262 - val_mae: 2.1348 - val_accuracy: 0.2726\n",
      "Epoch 207/300\n",
      "17037/17037 [==============================] - 8s 492us/step - loss: 164.2825 - mae: 3.0316 - accuracy: 0.2801 - val_loss: 15.1165 - val_mae: 1.6328 - val_accuracy: 0.2726\n",
      "Epoch 208/300\n",
      "17037/17037 [==============================] - 8s 479us/step - loss: 329.3842 - mae: 3.1727 - accuracy: 0.2810 - val_loss: 42.2065 - val_mae: 3.2385 - val_accuracy: 0.2726\n",
      "Epoch 209/300\n",
      "17037/17037 [==============================] - 8s 487us/step - loss: 382.1762 - mae: 3.1688 - accuracy: 0.2792 - val_loss: 4.6645 - val_mae: 1.3055 - val_accuracy: 0.2726\n",
      "Epoch 210/300\n",
      "17037/17037 [==============================] - 8s 478us/step - loss: 121.5258 - mae: 3.0413 - accuracy: 0.2802 - val_loss: 20.0075 - val_mae: 1.9309 - val_accuracy: 0.2726\n",
      "Epoch 211/300\n",
      "17037/17037 [==============================] - 8s 477us/step - loss: 206.4612 - mae: 3.1475 - accuracy: 0.2798 - val_loss: 3.4058 - val_mae: 1.1728 - val_accuracy: 0.2726\n",
      "Epoch 212/300\n",
      "17037/17037 [==============================] - 8s 491us/step - loss: 227.9494 - mae: 3.0160 - accuracy: 0.2800 - val_loss: 18.5818 - val_mae: 1.8348 - val_accuracy: 0.2726\n",
      "Epoch 213/300\n",
      "17037/17037 [==============================] - 8s 479us/step - loss: 136.5488 - mae: 3.1425 - accuracy: 0.2804 - val_loss: 9.9349 - val_mae: 1.5093 - val_accuracy: 0.2726\n",
      "Epoch 214/300\n",
      "17037/17037 [==============================] - 8s 485us/step - loss: 181.5995 - mae: 3.2491 - accuracy: 0.2797 - val_loss: 33.8132 - val_mae: 2.9097 - val_accuracy: 0.2726\n",
      "Epoch 215/300\n",
      "17037/17037 [==============================] - 9s 502us/step - loss: 131.2157 - mae: 3.1046 - accuracy: 0.2799 - val_loss: 6412.4180 - val_mae: 27.5856 - val_accuracy: 0.2726\n",
      "Epoch 216/300\n",
      "17037/17037 [==============================] - 8s 482us/step - loss: 411.0362 - mae: 3.0525 - accuracy: 0.2808 - val_loss: 8.0563 - val_mae: 1.2805 - val_accuracy: 0.2726\n",
      "Epoch 217/300\n",
      "17037/17037 [==============================] - 8s 484us/step - loss: 250.7632 - mae: 3.0871 - accuracy: 0.2808 - val_loss: 20.0671 - val_mae: 2.2293 - val_accuracy: 0.2726\n",
      "Epoch 218/300\n",
      "17037/17037 [==============================] - 9s 500us/step - loss: 346.1994 - mae: 3.0853 - accuracy: 0.2804 - val_loss: 14.7593 - val_mae: 1.6528 - val_accuracy: 0.2726\n",
      "Epoch 219/300\n",
      "17037/17037 [==============================] - 8s 480us/step - loss: 169.1866 - mae: 3.0415 - accuracy: 0.2798 - val_loss: 5.5061 - val_mae: 0.9285 - val_accuracy: 0.2725\n",
      "Epoch 220/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17037/17037 [==============================] - 8s 478us/step - loss: 277.0583 - mae: 2.9902 - accuracy: 0.2806 - val_loss: 24.3333 - val_mae: 2.5405 - val_accuracy: 0.2726\n",
      "Epoch 221/300\n",
      "17037/17037 [==============================] - 8s 482us/step - loss: 298.7797 - mae: 3.1433 - accuracy: 0.2817 - val_loss: 1.4432 - val_mae: 0.8432 - val_accuracy: 0.2726\n",
      "Epoch 222/300\n",
      "17037/17037 [==============================] - 8s 487us/step - loss: 227.1649 - mae: 3.2169 - accuracy: 0.2806 - val_loss: 7.1633 - val_mae: 1.5938 - val_accuracy: 0.2726\n",
      "Epoch 223/300\n",
      "17037/17037 [==============================] - 8s 483us/step - loss: 155.7723 - mae: 3.1173 - accuracy: 0.2799 - val_loss: 26.2230 - val_mae: 2.6908 - val_accuracy: 0.2726\n",
      "Epoch 224/300\n",
      "17037/17037 [==============================] - 8s 480us/step - loss: 159.5676 - mae: 3.1708 - accuracy: 0.2803 - val_loss: 6.6241 - val_mae: 1.4159 - val_accuracy: 0.2628\n",
      "Epoch 225/300\n",
      "17037/17037 [==============================] - 8s 479us/step - loss: 162.3710 - mae: 3.2867 - accuracy: 0.2710 - val_loss: 12.2382 - val_mae: 1.6154 - val_accuracy: 0.2726\n",
      "Epoch 226/300\n",
      "17037/17037 [==============================] - 8s 479us/step - loss: 169.4684 - mae: 3.2450 - accuracy: 0.2725 - val_loss: 22.5693 - val_mae: 2.1381 - val_accuracy: 0.2726\n",
      "Epoch 227/300\n",
      "17037/17037 [==============================] - 8s 479us/step - loss: 235.2230 - mae: 3.4109 - accuracy: 0.2715 - val_loss: 5.3324 - val_mae: 1.5731 - val_accuracy: 0.2139\n",
      "Epoch 228/300\n",
      "17037/17037 [==============================] - 8s 476us/step - loss: 157.6255 - mae: 3.3754 - accuracy: 0.2696 - val_loss: 33.5028 - val_mae: 3.1037 - val_accuracy: 0.2726\n",
      "Epoch 229/300\n",
      "17037/17037 [==============================] - 8s 490us/step - loss: 191.8499 - mae: 3.3567 - accuracy: 0.2737 - val_loss: 16.6361 - val_mae: 1.8555 - val_accuracy: 0.2701\n",
      "Epoch 230/300\n",
      "17037/17037 [==============================] - 8s 493us/step - loss: 218.5460 - mae: 3.2752 - accuracy: 0.2748 - val_loss: 21.1420 - val_mae: 2.2250 - val_accuracy: 0.2726\n",
      "Epoch 231/300\n",
      "17037/17037 [==============================] - 8s 478us/step - loss: 133.0622 - mae: 3.2229 - accuracy: 0.2762 - val_loss: 12.6108 - val_mae: 1.7604 - val_accuracy: 0.2726\n",
      "Epoch 232/300\n",
      "17037/17037 [==============================] - 8s 477us/step - loss: 278.5850 - mae: 3.3224 - accuracy: 0.2787 - val_loss: 9.6279 - val_mae: 1.6515 - val_accuracy: 0.2726\n",
      "Epoch 233/300\n",
      "17037/17037 [==============================] - 8s 497us/step - loss: 154.8797 - mae: 3.0850 - accuracy: 0.2783 - val_loss: 138.6088 - val_mae: 3.5298 - val_accuracy: 0.1329\n",
      "Epoch 234/300\n",
      "17037/17037 [==============================] - 9s 502us/step - loss: 539.3082 - mae: 3.2918 - accuracy: 0.2786 - val_loss: 11.9025 - val_mae: 1.7970 - val_accuracy: 0.2726\n",
      "Epoch 235/300\n",
      "17037/17037 [==============================] - 8s 479us/step - loss: 162.4717 - mae: 3.0558 - accuracy: 0.2791 - val_loss: 7.9914 - val_mae: 1.3146 - val_accuracy: 0.2726\n",
      "Epoch 236/300\n",
      "17037/17037 [==============================] - 8s 482us/step - loss: 255.9981 - mae: 3.0110 - accuracy: 0.2780 - val_loss: 5.5503 - val_mae: 1.2836 - val_accuracy: 0.2726\n",
      "Epoch 237/300\n",
      "17037/17037 [==============================] - 8s 484us/step - loss: 155.2303 - mae: 3.0179 - accuracy: 0.2774 - val_loss: 21.4419 - val_mae: 2.1498 - val_accuracy: 0.2716\n",
      "Epoch 238/300\n",
      "17037/17037 [==============================] - 8s 477us/step - loss: 678.7594 - mae: 3.1955 - accuracy: 0.2791 - val_loss: 10.9014 - val_mae: 2.1756 - val_accuracy: 0.2726\n",
      "Epoch 239/300\n",
      "17037/17037 [==============================] - 8s 481us/step - loss: 367.5144 - mae: 3.0907 - accuracy: 0.2770 - val_loss: 13.7961 - val_mae: 1.3618 - val_accuracy: 0.2726\n",
      "Epoch 240/300\n",
      "17037/17037 [==============================] - 8s 477us/step - loss: 183.9616 - mae: 3.0255 - accuracy: 0.2761 - val_loss: 95.4916 - val_mae: 4.7959 - val_accuracy: 0.2726\n",
      "Epoch 241/300\n",
      "17037/17037 [==============================] - 8s 480us/step - loss: 141.7462 - mae: 2.9564 - accuracy: 0.2780 - val_loss: 972.5057 - val_mae: 10.3780 - val_accuracy: 0.2726\n",
      "Epoch 242/300\n",
      "17037/17037 [==============================] - 8s 477us/step - loss: 180.2025 - mae: 2.9589 - accuracy: 0.2781 - val_loss: 30.7871 - val_mae: 2.7442 - val_accuracy: 0.2726\n",
      "Epoch 243/300\n",
      "17037/17037 [==============================] - 8s 482us/step - loss: 268.6180 - mae: 2.9910 - accuracy: 0.2776 - val_loss: 18.9947 - val_mae: 1.8369 - val_accuracy: 0.2726\n",
      "Epoch 244/300\n",
      "17037/17037 [==============================] - 8s 486us/step - loss: 186.9508 - mae: 2.9098 - accuracy: 0.2780 - val_loss: 30.1129 - val_mae: 2.1847 - val_accuracy: 0.2726\n",
      "Epoch 245/300\n",
      "17037/17037 [==============================] - 8s 487us/step - loss: 467.3863 - mae: 2.9659 - accuracy: 0.2778 - val_loss: 794.4902 - val_mae: 7.4426 - val_accuracy: 0.2726\n",
      "Epoch 246/300\n",
      "17037/17037 [==============================] - 8s 492us/step - loss: 381.4795 - mae: 3.0122 - accuracy: 0.2765 - val_loss: 13.0467 - val_mae: 1.6711 - val_accuracy: 0.2726\n",
      "Epoch 247/300\n",
      "17037/17037 [==============================] - 8s 482us/step - loss: 158.8822 - mae: 3.0018 - accuracy: 0.2775 - val_loss: 18.0168 - val_mae: 1.7155 - val_accuracy: 0.2726\n",
      "Epoch 248/300\n",
      "17037/17037 [==============================] - 8s 496us/step - loss: 229.0414 - mae: 3.0337 - accuracy: 0.2780 - val_loss: 4.1855 - val_mae: 0.9023 - val_accuracy: 0.2726\n",
      "Epoch 249/300\n",
      "17037/17037 [==============================] - 8s 486us/step - loss: 192.2007 - mae: 3.0155 - accuracy: 0.2795 - val_loss: 75.1132 - val_mae: 4.2331 - val_accuracy: 0.2726\n",
      "Epoch 250/300\n",
      "17037/17037 [==============================] - 8s 481us/step - loss: 195.2306 - mae: 2.9857 - accuracy: 0.2788 - val_loss: 27.4365 - val_mae: 2.5152 - val_accuracy: 0.2726\n",
      "Epoch 251/300\n",
      "17037/17037 [==============================] - 8s 481us/step - loss: 145.2638 - mae: 2.9389 - accuracy: 0.2782 - val_loss: 10.5719 - val_mae: 1.3066 - val_accuracy: 0.2714\n",
      "Epoch 252/300\n",
      "17037/17037 [==============================] - 8s 482us/step - loss: 134.0259 - mae: 2.8377 - accuracy: 0.2790 - val_loss: 13.3441 - val_mae: 1.8545 - val_accuracy: 0.2726\n",
      "Epoch 253/300\n",
      "17037/17037 [==============================] - 8s 481us/step - loss: 125.3712 - mae: 2.7928 - accuracy: 0.2794 - val_loss: 16.8978 - val_mae: 1.9772 - val_accuracy: 0.2726\n",
      "Epoch 254/300\n",
      "17037/17037 [==============================] - 8s 479us/step - loss: 166.9608 - mae: 2.8352 - accuracy: 0.2793 - val_loss: 5.2608 - val_mae: 1.2195 - val_accuracy: 0.2726\n",
      "Epoch 255/300\n",
      "17037/17037 [==============================] - 8s 484us/step - loss: 185.9748 - mae: 2.8018 - accuracy: 0.2799 - val_loss: 34.0519 - val_mae: 2.5997 - val_accuracy: 0.2726\n",
      "Epoch 256/300\n",
      "17037/17037 [==============================] - 8s 487us/step - loss: 124.3243 - mae: 2.9592 - accuracy: 0.2780 - val_loss: 11.9136 - val_mae: 1.5827 - val_accuracy: 0.2726\n",
      "Epoch 257/300\n",
      "17037/17037 [==============================] - 8s 481us/step - loss: 133.5914 - mae: 3.1383 - accuracy: 0.2803 - val_loss: 35.3422 - val_mae: 2.8140 - val_accuracy: 0.2726\n",
      "Epoch 258/300\n",
      "17037/17037 [==============================] - 8s 480us/step - loss: 144.1508 - mae: 3.0071 - accuracy: 0.2799 - val_loss: 50.2835 - val_mae: 3.0373 - val_accuracy: 0.2726\n",
      "Epoch 259/300\n",
      "17037/17037 [==============================] - 8s 495us/step - loss: 151.3234 - mae: 2.9159 - accuracy: 0.2788 - val_loss: 15.2114 - val_mae: 1.7627 - val_accuracy: 0.2726\n",
      "Epoch 260/300\n",
      "17037/17037 [==============================] - 8s 479us/step - loss: 118.8089 - mae: 2.9241 - accuracy: 0.2795 - val_loss: 25.1483 - val_mae: 2.4896 - val_accuracy: 0.2726\n",
      "Epoch 261/300\n",
      "17037/17037 [==============================] - 8s 482us/step - loss: 131.3554 - mae: 2.9385 - accuracy: 0.2803 - val_loss: 25.5625 - val_mae: 2.0900 - val_accuracy: 0.2726\n",
      "Epoch 262/300\n",
      "17037/17037 [==============================] - 8s 488us/step - loss: 164.6113 - mae: 2.9638 - accuracy: 0.2778 - val_loss: 8.7742 - val_mae: 1.4001 - val_accuracy: 0.2726\n",
      "Epoch 263/300\n",
      "17037/17037 [==============================] - 8s 499us/step - loss: 140.2665 - mae: 3.0360 - accuracy: 0.2809 - val_loss: 11.5405 - val_mae: 1.8919 - val_accuracy: 0.2726\n",
      "Epoch 264/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17037/17037 [==============================] - 8s 485us/step - loss: 121.4559 - mae: 2.9505 - accuracy: 0.2796 - val_loss: 22.5573 - val_mae: 1.9142 - val_accuracy: 0.2726\n",
      "Epoch 265/300\n",
      "17037/17037 [==============================] - 8s 480us/step - loss: 137.9383 - mae: 2.9446 - accuracy: 0.2787 - val_loss: 1.0349 - val_mae: 0.5017 - val_accuracy: 0.2726\n",
      "Epoch 266/300\n",
      "17037/17037 [==============================] - 8s 497us/step - loss: 162.8977 - mae: 2.9308 - accuracy: 0.2796 - val_loss: 39.6327 - val_mae: 2.9034 - val_accuracy: 0.2726\n",
      "Epoch 267/300\n",
      "17037/17037 [==============================] - 8s 488us/step - loss: 191.6948 - mae: 2.9069 - accuracy: 0.2792 - val_loss: 22.6483 - val_mae: 2.2243 - val_accuracy: 0.2726\n",
      "Epoch 268/300\n",
      "17037/17037 [==============================] - 8s 492us/step - loss: 104.2853 - mae: 2.8499 - accuracy: 0.2804 - val_loss: 16.9358 - val_mae: 1.8575 - val_accuracy: 0.2726\n",
      "Epoch 269/300\n",
      "17037/17037 [==============================] - 8s 474us/step - loss: 140.3056 - mae: 2.9405 - accuracy: 0.2792 - val_loss: 10.5964 - val_mae: 1.5328 - val_accuracy: 0.2726\n",
      "Epoch 270/300\n",
      "17037/17037 [==============================] - 8s 478us/step - loss: 125.0347 - mae: 2.8718 - accuracy: 0.2800 - val_loss: 14.3568 - val_mae: 1.5597 - val_accuracy: 0.2726\n",
      "Epoch 271/300\n",
      "17037/17037 [==============================] - 8s 482us/step - loss: 97.3951 - mae: 2.7859 - accuracy: 0.2802 - val_loss: 49.8041 - val_mae: 3.3294 - val_accuracy: 0.2726\n",
      "Epoch 272/300\n",
      "17037/17037 [==============================] - 8s 477us/step - loss: 134.7170 - mae: 2.8620 - accuracy: 0.2775 - val_loss: 37.9548 - val_mae: 2.5401 - val_accuracy: 0.2726\n",
      "Epoch 273/300\n",
      "17037/17037 [==============================] - 8s 476us/step - loss: 129.4326 - mae: 2.8531 - accuracy: 0.2791 - val_loss: 11.7871 - val_mae: 1.5028 - val_accuracy: 0.2726\n",
      "Epoch 274/300\n",
      "17037/17037 [==============================] - 8s 494us/step - loss: 109.8383 - mae: 2.8538 - accuracy: 0.2803 - val_loss: 48.0546 - val_mae: 2.1401 - val_accuracy: 0.2726\n",
      "Epoch 275/300\n",
      "17037/17037 [==============================] - 8s 480us/step - loss: 193.4482 - mae: 2.9221 - accuracy: 0.2786 - val_loss: 22.5239 - val_mae: 2.5837 - val_accuracy: 0.2726\n",
      "Epoch 276/300\n",
      "17037/17037 [==============================] - 8s 483us/step - loss: 125.9497 - mae: 2.8407 - accuracy: 0.2768 - val_loss: 4.5564 - val_mae: 1.0920 - val_accuracy: 0.2726\n",
      "Epoch 277/300\n",
      "17037/17037 [==============================] - 8s 492us/step - loss: 143.2673 - mae: 2.8692 - accuracy: 0.2811 - val_loss: 24.6356 - val_mae: 1.8872 - val_accuracy: 0.2726\n",
      "Epoch 278/300\n",
      "17037/17037 [==============================] - 8s 479us/step - loss: 118.8627 - mae: 2.8327 - accuracy: 0.2797 - val_loss: 3.0699 - val_mae: 0.8558 - val_accuracy: 0.2726\n",
      "Epoch 279/300\n",
      "17037/17037 [==============================] - 8s 480us/step - loss: 164.9528 - mae: 2.8840 - accuracy: 0.2753 - val_loss: 28.8734 - val_mae: 2.3458 - val_accuracy: 0.2726\n",
      "Epoch 280/300\n",
      "17037/17037 [==============================] - 8s 478us/step - loss: 132.9065 - mae: 2.9593 - accuracy: 0.2761 - val_loss: 24.4998 - val_mae: 2.0310 - val_accuracy: 0.2726\n",
      "Epoch 281/300\n",
      "17037/17037 [==============================] - 8s 482us/step - loss: 167.1209 - mae: 2.9075 - accuracy: 0.2790 - val_loss: 34.2519 - val_mae: 2.5804 - val_accuracy: 0.2726\n",
      "Epoch 282/300\n",
      "17037/17037 [==============================] - 9s 516us/step - loss: 163.9713 - mae: 2.8346 - accuracy: 0.2779 - val_loss: 2.0144 - val_mae: 0.7575 - val_accuracy: 0.2726\n",
      "Epoch 283/300\n",
      "17037/17037 [==============================] - 10s 576us/step - loss: 112.6566 - mae: 2.8443 - accuracy: 0.2792 - val_loss: 33.5140 - val_mae: 2.8180 - val_accuracy: 0.2726\n",
      "Epoch 284/300\n",
      "17037/17037 [==============================] - 9s 500us/step - loss: 111.4888 - mae: 2.8748 - accuracy: 0.2778 - val_loss: 44.8724 - val_mae: 3.3154 - val_accuracy: 0.2726\n",
      "Epoch 285/300\n",
      "17037/17037 [==============================] - 8s 490us/step - loss: 94.9216 - mae: 2.7451 - accuracy: 0.2803 - val_loss: 10.7533 - val_mae: 1.3835 - val_accuracy: 0.2726\n",
      "Epoch 286/300\n",
      "17037/17037 [==============================] - 8s 483us/step - loss: 124.6673 - mae: 2.7516 - accuracy: 0.2763 - val_loss: 2.9536 - val_mae: 0.9269 - val_accuracy: 0.2726\n",
      "Epoch 287/300\n",
      "17037/17037 [==============================] - 8s 483us/step - loss: 117.5639 - mae: 2.8051 - accuracy: 0.2799 - val_loss: 13.9441 - val_mae: 2.0222 - val_accuracy: 0.2726\n",
      "Epoch 288/300\n",
      "17037/17037 [==============================] - 9s 500us/step - loss: 131.7675 - mae: 2.8435 - accuracy: 0.2800 - val_loss: 36.0939 - val_mae: 2.5297 - val_accuracy: 0.2726\n",
      "Epoch 289/300\n",
      "17037/17037 [==============================] - 9s 500us/step - loss: 134.7611 - mae: 2.8081 - accuracy: 0.2783 - val_loss: 23.6475 - val_mae: 1.9751 - val_accuracy: 0.2726\n",
      "Epoch 290/300\n",
      "17037/17037 [==============================] - 8s 493us/step - loss: 222.9805 - mae: 2.8662 - accuracy: 0.2787 - val_loss: 22.3117 - val_mae: 1.5624 - val_accuracy: 0.2726\n",
      "Epoch 291/300\n",
      "17037/17037 [==============================] - 9s 500us/step - loss: 141.0078 - mae: 2.8232 - accuracy: 0.2790 - val_loss: 4.9053 - val_mae: 1.2803 - val_accuracy: 0.2726\n",
      "Epoch 292/300\n",
      "17037/17037 [==============================] - 8s 494us/step - loss: 986.4506 - mae: 2.9058 - accuracy: 0.2787 - val_loss: 15.3789 - val_mae: 1.7084 - val_accuracy: 0.2726\n",
      "Epoch 293/300\n",
      "17037/17037 [==============================] - 8s 478us/step - loss: 164.5221 - mae: 2.7264 - accuracy: 0.2787 - val_loss: 21.2208 - val_mae: 2.0851 - val_accuracy: 0.2726\n",
      "Epoch 294/300\n",
      "17037/17037 [==============================] - 8s 484us/step - loss: 104.6287 - mae: 2.7741 - accuracy: 0.2794 - val_loss: 4.7862 - val_mae: 1.1158 - val_accuracy: 0.2726\n",
      "Epoch 295/300\n",
      "17037/17037 [==============================] - 8s 481us/step - loss: 118.1540 - mae: 2.7350 - accuracy: 0.2751 - val_loss: 8.6559 - val_mae: 1.1553 - val_accuracy: 0.2726\n",
      "Epoch 296/300\n",
      "17037/17037 [==============================] - 8s 479us/step - loss: 141.1819 - mae: 2.7437 - accuracy: 0.2808 - val_loss: 35.4536 - val_mae: 2.5773 - val_accuracy: 0.2726\n",
      "Epoch 297/300\n",
      "17037/17037 [==============================] - 9s 516us/step - loss: 158.2005 - mae: 2.7550 - accuracy: 0.2763 - val_loss: 27.4042 - val_mae: 2.1814 - val_accuracy: 0.2726\n",
      "Epoch 298/300\n",
      "17037/17037 [==============================] - 8s 485us/step - loss: 86.1448 - mae: 2.5981 - accuracy: 0.2793 - val_loss: 0.9835 - val_mae: 0.6198 - val_accuracy: 0.2726\n",
      "Epoch 299/300\n",
      "17037/17037 [==============================] - 9s 510us/step - loss: 116.6056 - mae: 2.6667 - accuracy: 0.2799 - val_loss: 6.1208 - val_mae: 1.1318 - val_accuracy: 0.2726\n",
      "Epoch 300/300\n",
      "17037/17037 [==============================] - 8s 487us/step - loss: 117.8258 - mae: 2.6778 - accuracy: 0.2801 - val_loss: 3.6643 - val_mae: 0.8920 - val_accuracy: 0.2726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ecd8580c10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 300\n",
    "history = model.fit(train_data, train_label, epochs=EPOCHS, validation_split=0.2, verbose=1)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ece37cf910>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mae'][50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-556d8bde0bc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in models:\n",
    "    result.append(i.predict(test_data))\n",
    "predict = np.mean(result, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70596, 18)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"hold_d\"] = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"hold_d\"] = np.round(submission[\"hold_d\"]).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submit_id</th>\n",
       "      <th>hold_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IDX00001</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDX00002</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IDX00003</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IDX00004</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IDX00005</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70591</th>\n",
       "      <td>IDX70592</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70592</th>\n",
       "      <td>IDX70593</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70593</th>\n",
       "      <td>IDX70594</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70594</th>\n",
       "      <td>IDX70595</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70595</th>\n",
       "      <td>IDX70596</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70596 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submit_id  hold_d\n",
       "0      IDX00001     172\n",
       "1      IDX00002     379\n",
       "2      IDX00003     156\n",
       "3      IDX00004     264\n",
       "4      IDX00005      11\n",
       "...         ...     ...\n",
       "70591  IDX70592      29\n",
       "70592  IDX70593     118\n",
       "70593  IDX70594     989\n",
       "70594  IDX70595      12\n",
       "70595  IDX70596       7\n",
       "\n",
       "[70596 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"20211010_dnn1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 83.8147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
