{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_row\", 100)\n",
    "pd.set_option(\"display.max_column\", 100)\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"C:/Users/hu612/Desktop/School/sooda/Project/팀과제/민수서영우철/data/stk_hld_train.csv\")\n",
    "test = pd.read_csv(\"C:/Users/hu612/Desktop/School/sooda/Project/팀과제/민수서영우철/data/stk_hld_test.csv\")\n",
    "cus = pd.read_csv(\"C:/Users/hu612/Desktop/School/sooda/Project/팀과제/민수서영우철/data/cus_info.csv\")\n",
    "iem = pd.read_csv(\"C:/Users/hu612/Desktop/School/sooda/Project/팀과제/민수서영우철/data/iem_info_20210902.csv\")\n",
    "hist = pd.read_csv(\"C:/Users/hu612/Desktop/School/sooda/Project/팀과제/민수서영우철/data/stk_bnc_hist.csv\")\n",
    "submission = pd.read_csv(\"C:/Users/hu612/Desktop/School/sooda/Project/팀과제/민수서영우철/data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_id</th>\n",
       "      <th>iem_cd</th>\n",
       "      <th>byn_dt</th>\n",
       "      <th>hold_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A006360</td>\n",
       "      <td>20180726</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A005930</td>\n",
       "      <td>20180131</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A005070</td>\n",
       "      <td>20180517</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              act_id   iem_cd    byn_dt  \\\n",
       "0  0ad104dbed99be0cd858aa772765ddedade554601a981b...  A006360  20180726   \n",
       "1  0ad104dbed99be0cd858aa772765ddedade554601a981b...  A005930  20180131   \n",
       "2  0ad104dbed99be0cd858aa772765ddedade554601a981b...  A005070  20180517   \n",
       "\n",
       "   hold_d  \n",
       "0      11  \n",
       "1      80  \n",
       "2       5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_id</th>\n",
       "      <th>iem_cd</th>\n",
       "      <th>byn_dt</th>\n",
       "      <th>hist_d</th>\n",
       "      <th>submit_id</th>\n",
       "      <th>hold_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A032640</td>\n",
       "      <td>20200522</td>\n",
       "      <td>153</td>\n",
       "      <td>IDX00001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A160600</td>\n",
       "      <td>20190823</td>\n",
       "      <td>335</td>\n",
       "      <td>IDX00002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A234340</td>\n",
       "      <td>20200611</td>\n",
       "      <td>139</td>\n",
       "      <td>IDX00003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              act_id   iem_cd    byn_dt  \\\n",
       "0  0ad104dbed99be0cd858aa772765ddedade554601a981b...  A032640  20200522   \n",
       "1  0ad104dbed99be0cd858aa772765ddedade554601a981b...  A160600  20190823   \n",
       "2  0ad104dbed99be0cd858aa772765ddedade554601a981b...  A234340  20200611   \n",
       "\n",
       "   hist_d submit_id  hold_d  \n",
       "0     153  IDX00001       0  \n",
       "1     335  IDX00002       0  \n",
       "2     139  IDX00003       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"hist_d\"] = train[\"hold_d\"]*0.877\n",
    "train.hist_d = np.trunc(train[\"hist_d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_id</th>\n",
       "      <th>iem_cd</th>\n",
       "      <th>byn_dt</th>\n",
       "      <th>hold_d</th>\n",
       "      <th>hist_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A006360</td>\n",
       "      <td>20180726</td>\n",
       "      <td>11</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A005930</td>\n",
       "      <td>20180131</td>\n",
       "      <td>80</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A005070</td>\n",
       "      <td>20180517</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A003520</td>\n",
       "      <td>20201112</td>\n",
       "      <td>22</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A002310</td>\n",
       "      <td>20180905</td>\n",
       "      <td>324</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681467</th>\n",
       "      <td>4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...</td>\n",
       "      <td>A260660</td>\n",
       "      <td>20180831</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681468</th>\n",
       "      <td>4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...</td>\n",
       "      <td>A271980</td>\n",
       "      <td>20201027</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681469</th>\n",
       "      <td>4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...</td>\n",
       "      <td>A289080</td>\n",
       "      <td>20181121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681470</th>\n",
       "      <td>4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...</td>\n",
       "      <td>A307930</td>\n",
       "      <td>20200214</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681471</th>\n",
       "      <td>4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...</td>\n",
       "      <td>A308100</td>\n",
       "      <td>20200116</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>681472 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   act_id   iem_cd    byn_dt  \\\n",
       "0       0ad104dbed99be0cd858aa772765ddedade554601a981b...  A006360  20180726   \n",
       "1       0ad104dbed99be0cd858aa772765ddedade554601a981b...  A005930  20180131   \n",
       "2       0ad104dbed99be0cd858aa772765ddedade554601a981b...  A005070  20180517   \n",
       "3       0ad104dbed99be0cd858aa772765ddedade554601a981b...  A003520  20201112   \n",
       "4       0ad104dbed99be0cd858aa772765ddedade554601a981b...  A002310  20180905   \n",
       "...                                                   ...      ...       ...   \n",
       "681467  4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...  A260660  20180831   \n",
       "681468  4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...  A271980  20201027   \n",
       "681469  4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...  A289080  20181121   \n",
       "681470  4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...  A307930  20200214   \n",
       "681471  4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...  A308100  20200116   \n",
       "\n",
       "        hold_d  hist_d  \n",
       "0           11     9.0  \n",
       "1           80    70.0  \n",
       "2            5     4.0  \n",
       "3           22    19.0  \n",
       "4          324   284.0  \n",
       "...        ...     ...  \n",
       "681467       1     0.0  \n",
       "681468       1     0.0  \n",
       "681469       1     0.0  \n",
       "681470       1     0.0  \n",
       "681471       1     0.0  \n",
       "\n",
       "[681472 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train과 test에 고객정보(cus_info)와 주식정보(iem_info)를 추가하겠습니다.\n",
    "\n",
    "train_data = pd.merge(train, cus, how = \"left\", on = [\"act_id\"])\n",
    "train_data = pd.merge(train_data, iem, how = \"left\", on = [\"iem_cd\"])\n",
    "\n",
    "test_data = pd.merge(test, cus, how = \"left\", on = [\"act_id\"])\n",
    "test_data = pd.merge(test_data, iem, how = \"left\", on = [\"iem_cd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681472, 18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data에서 Y값을 추출한 후 hold_d column을 지워주겠습니다.\n",
    "\n",
    "train_label = train_data[\"hold_d\"]\n",
    "train_data.drop([\"hold_d\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가적으로 약간의 전처리를 통해 train data와 test data를 구성하겠습니다.\n",
    "\n",
    "hist[\"stk_p\"] = hist[\"tot_aet_amt\"] / hist[\"bnc_qty\"]\n",
    "hist = hist.fillna(0)\n",
    "\n",
    "train_data = pd.merge(train_data, hist, how = \"left\", on = [\"act_id\", \"iem_cd\"])\n",
    "train_data = train_data[(train_data[\"byn_dt\"] == train_data[\"bse_dt\"])]\n",
    "train_data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "test_data = pd.merge(test_data, hist, how = \"left\", on = [\"act_id\", \"iem_cd\"])\n",
    "test_data = test_data[(test_data[\"byn_dt\"] == test_data[\"bse_dt\"])]\n",
    "test_data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "train_data = train_data.drop([\"act_id\", \"iem_cd\", \"byn_dt\", \"bse_dt\"], axis = 1)\n",
    "test_data = test_data.drop([\"act_id\", \"iem_cd\", \"byn_dt\", \"submit_id\", \"hold_d\", \"bse_dt\"], axis = 1)\n",
    "\n",
    "L_encoder = LabelEncoder()\n",
    "L_encoder.fit(iem[\"iem_krl_nm\"])\n",
    "train_data[\"iem_krl_nm\"] = L_encoder.transform(train_data[\"iem_krl_nm\"])\n",
    "test_data[\"iem_krl_nm\"] = L_encoder.transform(test_data[\"iem_krl_nm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hist_d</th>\n",
       "      <th>sex_dit_cd</th>\n",
       "      <th>cus_age_stn_cd</th>\n",
       "      <th>ivs_icn_cd</th>\n",
       "      <th>cus_aet_stn_cd</th>\n",
       "      <th>mrz_pdt_tp_sgm_cd</th>\n",
       "      <th>lsg_sgm_cd</th>\n",
       "      <th>tco_cus_grd_cd</th>\n",
       "      <th>tot_ivs_te_sgm_cd</th>\n",
       "      <th>mrz_btp_dit_cd</th>\n",
       "      <th>iem_krl_nm</th>\n",
       "      <th>btp_cfc_cd</th>\n",
       "      <th>mkt_pr_tal_scl_tp_cd</th>\n",
       "      <th>stk_dit_cd</th>\n",
       "      <th>bnc_qty</th>\n",
       "      <th>tot_aet_amt</th>\n",
       "      <th>stk_par_pr</th>\n",
       "      <th>stk_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>274.0</td>\n",
       "      <td>11782000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>43000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1361</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4990000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2495000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2530</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>786.0</td>\n",
       "      <td>14619600.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>18600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hist_d  sex_dit_cd  cus_age_stn_cd  ivs_icn_cd  cus_aet_stn_cd  \\\n",
       "0     9.0           1               9           3               2   \n",
       "1    70.0           1               9           3               2   \n",
       "2     4.0           1               9           3               2   \n",
       "\n",
       "   mrz_pdt_tp_sgm_cd  lsg_sgm_cd  tco_cus_grd_cd  tot_ivs_te_sgm_cd  \\\n",
       "0                  2           9               5                  5   \n",
       "1                  2           9               5                  5   \n",
       "2                  2           9               5                  5   \n",
       "\n",
       "   mrz_btp_dit_cd  iem_krl_nm  btp_cfc_cd  mkt_pr_tal_scl_tp_cd  stk_dit_cd  \\\n",
       "0               8         101           1                     1           1   \n",
       "1               8        1361           9                     1           1   \n",
       "2               8        2530          12                     2          99   \n",
       "\n",
       "   bnc_qty  tot_aet_amt  stk_par_pr      stk_p  \n",
       "0    274.0   11782000.0      5000.0    43000.0  \n",
       "1      2.0    4990000.0      5000.0  2495000.0  \n",
       "2    786.0   14619600.0      1000.0    18600.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hist_d</th>\n",
       "      <th>sex_dit_cd</th>\n",
       "      <th>cus_age_stn_cd</th>\n",
       "      <th>ivs_icn_cd</th>\n",
       "      <th>cus_aet_stn_cd</th>\n",
       "      <th>mrz_pdt_tp_sgm_cd</th>\n",
       "      <th>lsg_sgm_cd</th>\n",
       "      <th>tco_cus_grd_cd</th>\n",
       "      <th>tot_ivs_te_sgm_cd</th>\n",
       "      <th>mrz_btp_dit_cd</th>\n",
       "      <th>iem_krl_nm</th>\n",
       "      <th>btp_cfc_cd</th>\n",
       "      <th>mkt_pr_tal_scl_tp_cd</th>\n",
       "      <th>stk_dit_cd</th>\n",
       "      <th>bnc_qty</th>\n",
       "      <th>tot_aet_amt</th>\n",
       "      <th>stk_par_pr</th>\n",
       "      <th>stk_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>274.0</td>\n",
       "      <td>11782000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>43000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1361</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4990000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2495000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2530</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>786.0</td>\n",
       "      <td>14619600.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>18600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1969</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>462000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>7700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>284.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1696</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>183.0</td>\n",
       "      <td>8125200.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>44400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681467</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1752</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>199.0</td>\n",
       "      <td>3532250.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>17750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681468</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2344</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>488.0</td>\n",
       "      <td>22960400.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>47050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681469</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>521</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>2210.0</td>\n",
       "      <td>9204650.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>4165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681470</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2460</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>285.0</td>\n",
       "      <td>2721750.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>9550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681471</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>750</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>310.0</td>\n",
       "      <td>4030000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>13000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>681472 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hist_d  sex_dit_cd  cus_age_stn_cd  ivs_icn_cd  cus_aet_stn_cd  \\\n",
       "0          9.0           1               9           3               2   \n",
       "1         70.0           1               9           3               2   \n",
       "2          4.0           1               9           3               2   \n",
       "3         19.0           1               9           3               2   \n",
       "4        284.0           1               9           3               2   \n",
       "...        ...         ...             ...         ...             ...   \n",
       "681467     0.0           1               4           4               2   \n",
       "681468     0.0           1               4           4               2   \n",
       "681469     0.0           1               4           4               2   \n",
       "681470     0.0           1               4           4               2   \n",
       "681471     0.0           1               4           4               2   \n",
       "\n",
       "        mrz_pdt_tp_sgm_cd  lsg_sgm_cd  tco_cus_grd_cd  tot_ivs_te_sgm_cd  \\\n",
       "0                       2           9               5                  5   \n",
       "1                       2           9               5                  5   \n",
       "2                       2           9               5                  5   \n",
       "3                       2           9               5                  5   \n",
       "4                       2           9               5                  5   \n",
       "...                   ...         ...             ...                ...   \n",
       "681467                  2           3               4                  3   \n",
       "681468                  2           3               4                  3   \n",
       "681469                  2           3               4                  3   \n",
       "681470                  2           3               4                  3   \n",
       "681471                  2           3               4                  3   \n",
       "\n",
       "        mrz_btp_dit_cd  iem_krl_nm  btp_cfc_cd  mkt_pr_tal_scl_tp_cd  \\\n",
       "0                    8         101           1                     1   \n",
       "1                    8        1361           9                     1   \n",
       "2                    8        2530          12                     2   \n",
       "3                    8        1969           8                     2   \n",
       "4                    8        1696          10                     3   \n",
       "...                ...         ...         ...                   ...   \n",
       "681467               8        1752          10                     3   \n",
       "681468               8        2344           8                     2   \n",
       "681469               8         521           2                     2   \n",
       "681470               8        2460           2                     3   \n",
       "681471               8         750           7                     3   \n",
       "\n",
       "        stk_dit_cd  bnc_qty  tot_aet_amt  stk_par_pr      stk_p  \n",
       "0                1    274.0   11782000.0      5000.0    43000.0  \n",
       "1                1      2.0    4990000.0      5000.0  2495000.0  \n",
       "2               99    786.0   14619600.0      1000.0    18600.0  \n",
       "3                1     60.0     462000.0       500.0     7700.0  \n",
       "4               99    183.0    8125200.0      5000.0    44400.0  \n",
       "...            ...      ...          ...         ...        ...  \n",
       "681467          99    199.0    3532250.0       500.0    17750.0  \n",
       "681468          99    488.0   22960400.0       500.0    47050.0  \n",
       "681469          99   2210.0    9204650.0       500.0     4165.0  \n",
       "681470          99    285.0    2721750.0       500.0     9550.0  \n",
       "681471          99    310.0    4030000.0       500.0    13000.0  \n",
       "\n",
       "[681472 rows x 18 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hist_d</th>\n",
       "      <th>sex_dit_cd</th>\n",
       "      <th>cus_age_stn_cd</th>\n",
       "      <th>ivs_icn_cd</th>\n",
       "      <th>cus_aet_stn_cd</th>\n",
       "      <th>mrz_pdt_tp_sgm_cd</th>\n",
       "      <th>lsg_sgm_cd</th>\n",
       "      <th>tco_cus_grd_cd</th>\n",
       "      <th>tot_ivs_te_sgm_cd</th>\n",
       "      <th>mrz_btp_dit_cd</th>\n",
       "      <th>iem_krl_nm</th>\n",
       "      <th>btp_cfc_cd</th>\n",
       "      <th>mkt_pr_tal_scl_tp_cd</th>\n",
       "      <th>stk_dit_cd</th>\n",
       "      <th>bnc_qty</th>\n",
       "      <th>tot_aet_amt</th>\n",
       "      <th>stk_par_pr</th>\n",
       "      <th>stk_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>418</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>300.0</td>\n",
       "      <td>3945000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>13150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>335</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2230</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>198.0</td>\n",
       "      <td>2524500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>12750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1515</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>138.0</td>\n",
       "      <td>4291800.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>31100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hist_d  sex_dit_cd  cus_age_stn_cd  ivs_icn_cd  cus_aet_stn_cd  \\\n",
       "0     153           1               9           3               2   \n",
       "1     335           1               9           3               2   \n",
       "2     139           1               9           3               2   \n",
       "\n",
       "   mrz_pdt_tp_sgm_cd  lsg_sgm_cd  tco_cus_grd_cd  tot_ivs_te_sgm_cd  \\\n",
       "0                  2           9               5                  5   \n",
       "1                  2           9               5                  5   \n",
       "2                  2           9               5                  5   \n",
       "\n",
       "   mrz_btp_dit_cd  iem_krl_nm  btp_cfc_cd  mkt_pr_tal_scl_tp_cd  stk_dit_cd  \\\n",
       "0               8         418           4                     1           1   \n",
       "1               8        2230          10                     3          99   \n",
       "2               8        1515          13                     2          99   \n",
       "\n",
       "   bnc_qty  tot_aet_amt  stk_par_pr    stk_p  \n",
       "0    300.0    3945000.0      5000.0  13150.0  \n",
       "1    198.0    2524500.0       500.0  12750.0  \n",
       "2    138.0    4291800.0       500.0  31100.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.reset_index(drop = True, inplace=True)\n",
    "train_label.reset_index(drop = True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681472, 18)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681472,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_label.values.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681472, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_x, val_x, train_y, val_y = train_test_split(train_data, train_label, test_size=0.2, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_x.shape)\n",
    "# print(train_y.shape)\n",
    "# print(val_x.shape)\n",
    "# print(val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(16,input_shape=[18], activation='relu'),\n",
    "        layers.Dense(8,input_shape=[16], activation='relu'),\n",
    "        layers.Dense(4,input_shape=[8], activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                304       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 481\n",
      "Trainable params: 481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17037/17037 [==============================] - 46s 3ms/step - loss: 457590.1371 - mae: 32.1539 - val_loss: 478.8219 - val_mae: 13.5001\n",
      "Epoch 2/500\n",
      "17037/17037 [==============================] - 34s 2ms/step - loss: 3340.2007 - mae: 23.5209 - val_loss: 530.7282 - val_mae: 17.2296\n",
      "Epoch 3/500\n",
      "17037/17037 [==============================] - 43s 3ms/step - loss: 5707.3385 - mae: 26.1540 - val_loss: 528.6727 - val_mae: 17.6533\n",
      "Epoch 4/500\n",
      "17037/17037 [==============================] - 42s 2ms/step - loss: 242096.5235 - mae: 30.4474 - val_loss: 3460.3550 - val_mae: 17.0258\n",
      "Epoch 5/500\n",
      "17037/17037 [==============================] - 43s 3ms/step - loss: 28205.4300 - mae: 26.3285 - val_loss: 455.5452 - val_mae: 15.5184\n",
      "Epoch 6/500\n",
      "17037/17037 [==============================] - 44s 3ms/step - loss: 68115.8822 - mae: 25.1449 - val_loss: 326.3655 - val_mae: 13.3114\n",
      "Epoch 7/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 55359.0677 - mae: 24.1311 - val_loss: 404.4175 - val_mae: 13.4827\n",
      "Epoch 8/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 62270.9742 - mae: 21.1344 - val_loss: 385.5806 - val_mae: 12.7567\n",
      "Epoch 9/500\n",
      "17037/17037 [==============================] - 45s 3ms/step - loss: 12892.0517 - mae: 19.0582 - val_loss: 339.2952 - val_mae: 11.5033\n",
      "Epoch 10/500\n",
      "17037/17037 [==============================] - 42s 2ms/step - loss: 22018.9374 - mae: 18.3815 - val_loss: 226.2626 - val_mae: 9.8332\n",
      "Epoch 11/500\n",
      "17037/17037 [==============================] - 44s 3ms/step - loss: 32414.9680 - mae: 16.5864 - val_loss: 250.5584 - val_mae: 9.9339\n",
      "Epoch 12/500\n",
      "17037/17037 [==============================] - 45s 3ms/step - loss: 15441.7490 - mae: 16.9335 - val_loss: 253.8755 - val_mae: 9.8477\n",
      "Epoch 13/500\n",
      "17037/17037 [==============================] - 42s 2ms/step - loss: 29184.2919 - mae: 16.3246 - val_loss: 269.6168 - val_mae: 10.1285\n",
      "Epoch 14/500\n",
      "17037/17037 [==============================] - 38s 2ms/step - loss: 9026.5864 - mae: 15.1861 - val_loss: 244.2509 - val_mae: 9.3912\n",
      "Epoch 15/500\n",
      "17037/17037 [==============================] - 34s 2ms/step - loss: 6766.0607 - mae: 15.5588 - val_loss: 344.1581 - val_mae: 10.9809\n",
      "Epoch 16/500\n",
      "17037/17037 [==============================] - 40s 2ms/step - loss: 5357.2860 - mae: 15.5928 - val_loss: 217.8368 - val_mae: 9.1611\n",
      "Epoch 17/500\n",
      "17037/17037 [==============================] - 40s 2ms/step - loss: 10100.6879 - mae: 15.3261 - val_loss: 321.2784 - val_mae: 11.2439\n",
      "Epoch 18/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 3821.3215 - mae: 15.5903 - val_loss: 237.6985 - val_mae: 9.2808\n",
      "Epoch 19/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 6283.5072 - mae: 15.5998 - val_loss: 167.9054 - val_mae: 8.0341\n",
      "Epoch 20/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 23561.0872 - mae: 16.2497 - val_loss: 159.6053 - val_mae: 9.8870\n",
      "Epoch 21/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 11903.2554 - mae: 15.9788 - val_loss: 161.9526 - val_mae: 8.0790\n",
      "Epoch 22/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 13716.0103 - mae: 16.8119 - val_loss: 391.2844 - val_mae: 11.4479\n",
      "Epoch 23/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 11077.2125 - mae: 16.5056 - val_loss: 268.1827 - val_mae: 10.1852\n",
      "Epoch 24/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 184312.1143 - mae: 19.8980 - val_loss: 202.4170 - val_mae: 9.5500\n",
      "Epoch 25/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 7462.2021 - mae: 16.6218 - val_loss: 232.2223 - val_mae: 9.0686\n",
      "Epoch 26/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 27124.3607 - mae: 17.1541 - val_loss: 243.3578 - val_mae: 8.6972\n",
      "Epoch 27/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 9511.8130 - mae: 14.8141 - val_loss: 233.5932 - val_mae: 8.8096\n",
      "Epoch 28/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 6537.7919 - mae: 13.5368 - val_loss: 165.9460 - val_mae: 7.2072\n",
      "Epoch 29/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 6855.3397 - mae: 12.1876 - val_loss: 203.9664 - val_mae: 8.3896\n",
      "Epoch 30/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 2885.0915 - mae: 11.3006 - val_loss: 94.1913 - val_mae: 6.4121\n",
      "Epoch 31/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 6059.6687 - mae: 10.9932 - val_loss: 208.4608 - val_mae: 7.5835\n",
      "Epoch 32/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 3580.1237 - mae: 10.0973 - val_loss: 98.4982 - val_mae: 5.5608\n",
      "Epoch 33/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 4032.0054 - mae: 10.4056 - val_loss: 182.1990 - val_mae: 7.3772\n",
      "Epoch 34/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 8777.9889 - mae: 10.4495 - val_loss: 118.2864 - val_mae: 6.2202\n",
      "Epoch 35/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 2271.4196 - mae: 9.3923 - val_loss: 257.3723 - val_mae: 8.5475\n",
      "Epoch 36/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1598.7451 - mae: 9.0854 - val_loss: 29.6795 - val_mae: 3.5282\n",
      "Epoch 37/500\n",
      "17037/17037 [==============================] - 40s 2ms/step - loss: 1455.4834 - mae: 8.2755 - val_loss: 84.0426 - val_mae: 4.7052\n",
      "Epoch 38/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1074.9740 - mae: 8.2609 - val_loss: 98.2589 - val_mae: 5.0999\n",
      "Epoch 39/500\n",
      "17037/17037 [==============================] - 40s 2ms/step - loss: 910.7458 - mae: 8.0883 - val_loss: 65.1993 - val_mae: 4.2416\n",
      "Epoch 40/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1100.8412 - mae: 8.0572 - val_loss: 89.1261 - val_mae: 4.8245\n",
      "Epoch 41/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1198.3858 - mae: 7.5284 - val_loss: 63.0342 - val_mae: 3.8277\n",
      "Epoch 42/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1664.2366 - mae: 7.6039 - val_loss: 255.3400 - val_mae: 10.5483\n",
      "Epoch 43/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1006.3189 - mae: 7.4152 - val_loss: 118189.3828 - val_mae: 115.9473\n",
      "Epoch 44/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1818.6083 - mae: 7.3891 - val_loss: 62.5647 - val_mae: 4.5496\n",
      "Epoch 45/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1079.8508 - mae: 7.2447 - val_loss: 44.1061 - val_mae: 4.3647\n",
      "Epoch 46/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 948.3071 - mae: 6.7641 - val_loss: 70.7009 - val_mae: 4.7276\n",
      "Epoch 47/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 696.0392 - mae: 6.6280 - val_loss: 88.1098 - val_mae: 5.2837\n",
      "Epoch 48/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1366.6620 - mae: 6.7852 - val_loss: 84.7169 - val_mae: 4.6869\n",
      "Epoch 49/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 742.4544 - mae: 6.6961 - val_loss: 101.7786 - val_mae: 4.9980\n",
      "Epoch 50/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 835.1737 - mae: 7.0125 - val_loss: 125.9342 - val_mae: 5.4093\n",
      "Epoch 51/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1008.7524 - mae: 6.6642 - val_loss: 24.0168 - val_mae: 3.5208\n",
      "Epoch 52/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 636.8020 - mae: 6.4415 - val_loss: 156.0182 - val_mae: 6.0547\n",
      "Epoch 53/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 805.0585 - mae: 6.7490 - val_loss: 35.0115 - val_mae: 3.7509\n",
      "Epoch 54/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 857.9225 - mae: 6.2433 - val_loss: 40.7431 - val_mae: 3.4787\n",
      "Epoch 55/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 761.6329 - mae: 6.5035 - val_loss: 75.2411 - val_mae: 4.4194\n",
      "Epoch 56/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 617.3620 - mae: 6.3085 - val_loss: 45.0082 - val_mae: 3.1692\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17037/17037 [==============================] - 41s 2ms/step - loss: 568.6163 - mae: 6.2504 - val_loss: 96.9667 - val_mae: 4.9294\n",
      "Epoch 58/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 720.5664 - mae: 6.3326 - val_loss: 78.4546 - val_mae: 4.1248\n",
      "Epoch 59/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 651.2444 - mae: 6.4259 - val_loss: 42.0433 - val_mae: 3.4238\n",
      "Epoch 60/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 8741.6851 - mae: 6.8266 - val_loss: 27.1622 - val_mae: 3.4067\n",
      "Epoch 61/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 2449.9486 - mae: 6.7248 - val_loss: 88.9846 - val_mae: 5.2851\n",
      "Epoch 62/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 682.0690 - mae: 6.5088 - val_loss: 89.4748 - val_mae: 4.9150\n",
      "Epoch 63/500\n",
      "17037/17037 [==============================] - 42s 2ms/step - loss: 1429.0447 - mae: 7.0062 - val_loss: 145.1348 - val_mae: 5.7611\n",
      "Epoch 64/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 649.3183 - mae: 6.8393 - val_loss: 62.8748 - val_mae: 3.9272\n",
      "Epoch 65/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1946.8305 - mae: 6.9453 - val_loss: 105.5872 - val_mae: 4.9427\n",
      "Epoch 66/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 801.9382 - mae: 6.8036 - val_loss: 18.4656 - val_mae: 2.9953\n",
      "Epoch 67/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 884.2876 - mae: 6.7016 - val_loss: 62.9860 - val_mae: 4.2041\n",
      "Epoch 68/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1842.2938 - mae: 6.9539 - val_loss: 47.3315 - val_mae: 3.4307\n",
      "Epoch 69/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 803.5775 - mae: 6.6390 - val_loss: 39.1950 - val_mae: 4.4618\n",
      "Epoch 70/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1577.9465 - mae: 6.6248 - val_loss: 72.2516 - val_mae: 4.0585\n",
      "Epoch 71/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 941.5268 - mae: 6.6910 - val_loss: 297.3784 - val_mae: 11.5102\n",
      "Epoch 72/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 2607.9497 - mae: 7.1739 - val_loss: 111.5300 - val_mae: 5.3403\n",
      "Epoch 73/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1019.6826 - mae: 7.2225 - val_loss: 25.0057 - val_mae: 2.6613\n",
      "Epoch 74/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 801.7091 - mae: 6.5844 - val_loss: 22.6185 - val_mae: 2.5956\n",
      "Epoch 75/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 2174.8359 - mae: 6.9627 - val_loss: 147.3620 - val_mae: 6.2249\n",
      "Epoch 76/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 831.7977 - mae: 6.9636 - val_loss: 51.7805 - val_mae: 4.0007\n",
      "Epoch 77/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 828.7986 - mae: 6.5960 - val_loss: 833.0698 - val_mae: 16.6418\n",
      "Epoch 78/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 6156.5560 - mae: 6.8797 - val_loss: 81.8012 - val_mae: 4.4924\n",
      "Epoch 79/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 848.0227 - mae: 6.8897 - val_loss: 82.3759 - val_mae: 5.2384\n",
      "Epoch 80/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1048.9761 - mae: 6.9604 - val_loss: 182.0246 - val_mae: 6.7301\n",
      "Epoch 81/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 4223.5157 - mae: 6.7707 - val_loss: 15.2250 - val_mae: 2.7934\n",
      "Epoch 82/500\n",
      "17037/17037 [==============================] - 40s 2ms/step - loss: 819.1409 - mae: 6.8447 - val_loss: 84.8637 - val_mae: 4.5847\n",
      "Epoch 83/500\n",
      "17037/17037 [==============================] - 40s 2ms/step - loss: 1126.6312 - mae: 7.2464 - val_loss: 46.6484 - val_mae: 3.2862\n",
      "Epoch 84/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 778.0436 - mae: 6.4804 - val_loss: 67.9055 - val_mae: 4.1838\n",
      "Epoch 85/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 939.3800 - mae: 6.7295 - val_loss: 1007.9291 - val_mae: 23.6418\n",
      "Epoch 86/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 697.4759 - mae: 6.5358 - val_loss: 97.8481 - val_mae: 4.8356\n",
      "Epoch 87/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 840.4184 - mae: 6.5904 - val_loss: 39.1147 - val_mae: 3.4873\n",
      "Epoch 88/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 700.9614 - mae: 6.4877 - val_loss: 41.6036 - val_mae: 2.9595\n",
      "Epoch 89/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 688.6357 - mae: 6.3069 - val_loss: 48.4318 - val_mae: 3.3479\n",
      "Epoch 90/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 808.9681 - mae: 6.5029 - val_loss: 145.6497 - val_mae: 6.4606\n",
      "Epoch 91/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 754.6553 - mae: 6.3322 - val_loss: 66.7377 - val_mae: 4.2037\n",
      "Epoch 92/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1189.7496 - mae: 6.7209 - val_loss: 151.4149 - val_mae: 6.4038\n",
      "Epoch 93/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 794.0481 - mae: 6.5026 - val_loss: 75.1684 - val_mae: 4.7670\n",
      "Epoch 94/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 3160.4444 - mae: 6.4294 - val_loss: 43.9651 - val_mae: 3.4096\n",
      "Epoch 95/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 3203.5365 - mae: 6.8144 - val_loss: 70.7694 - val_mae: 4.2942\n",
      "Epoch 96/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1027.6142 - mae: 6.1496 - val_loss: 126.3296 - val_mae: 5.7540\n",
      "Epoch 97/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1046.3514 - mae: 6.3361 - val_loss: 90.7618 - val_mae: 5.0373\n",
      "Epoch 98/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 652.8851 - mae: 6.0725 - val_loss: 19.5787 - val_mae: 2.5410\n",
      "Epoch 99/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 709.7953 - mae: 6.0556 - val_loss: 77.4313 - val_mae: 4.4563\n",
      "Epoch 100/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 587.7618 - mae: 6.3376 - val_loss: 80.3432 - val_mae: 4.4500\n",
      "Epoch 101/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 731.7823 - mae: 6.5949 - val_loss: 209.5039 - val_mae: 7.3092\n",
      "Epoch 102/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 739.2537 - mae: 6.1547 - val_loss: 52.5887 - val_mae: 4.5674\n",
      "Epoch 103/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1154.8114 - mae: 6.2753 - val_loss: 67.1063 - val_mae: 5.9057\n",
      "Epoch 104/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1157.4915 - mae: 6.0356 - val_loss: 188.0761 - val_mae: 6.8891\n",
      "Epoch 105/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1409.1555 - mae: 6.0740 - val_loss: 134.8928 - val_mae: 6.1889\n",
      "Epoch 106/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 701.6189 - mae: 6.2686 - val_loss: 86.7789 - val_mae: 4.4337\n",
      "Epoch 107/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 958.9242 - mae: 6.6608 - val_loss: 53.3530 - val_mae: 3.9532\n",
      "Epoch 108/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 2035.5084 - mae: 6.3570 - val_loss: 48.0603 - val_mae: 3.4225\n",
      "Epoch 109/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 867.0397 - mae: 6.1189 - val_loss: 81.0400 - val_mae: 4.4736\n",
      "Epoch 110/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 724.9004 - mae: 6.6503 - val_loss: 122.6561 - val_mae: 5.6334\n",
      "Epoch 111/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 609.6800 - mae: 5.9965 - val_loss: 99.7310 - val_mae: 5.2587\n",
      "Epoch 112/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 724.5905 - mae: 6.2511 - val_loss: 41.9834 - val_mae: 3.3404\n",
      "Epoch 113/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1059.2676 - mae: 6.6339 - val_loss: 14.9822 - val_mae: 2.4001\n",
      "Epoch 114/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17037/17037 [==============================] - 41s 2ms/step - loss: 804.2898 - mae: 6.3981 - val_loss: 50.5380 - val_mae: 3.6194\n",
      "Epoch 115/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 705.9674 - mae: 6.1732 - val_loss: 105.6679 - val_mae: 5.3453\n",
      "Epoch 116/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 3166.2396 - mae: 6.6265 - val_loss: 27.7425 - val_mae: 2.8678\n",
      "Epoch 117/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 740.5874 - mae: 6.0261 - val_loss: 60.7702 - val_mae: 3.9047\n",
      "Epoch 118/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 518.9813 - mae: 5.5721 - val_loss: 71.1187 - val_mae: 3.9274\n",
      "Epoch 119/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 751.4308 - mae: 5.9710 - val_loss: 25.7706 - val_mae: 3.2371\n",
      "Epoch 120/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 565.4971 - mae: 6.0096 - val_loss: 362.8477 - val_mae: 5.2835\n",
      "Epoch 121/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 966.2295 - mae: 5.7082 - val_loss: 7.4121 - val_mae: 1.6172\n",
      "Epoch 122/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 927.8343 - mae: 5.8300 - val_loss: 8.6205 - val_mae: 2.2585\n",
      "Epoch 123/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 399.8983 - mae: 5.4106 - val_loss: 11.1705 - val_mae: 2.0527\n",
      "Epoch 124/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 499.1616 - mae: 5.2796 - val_loss: 13.2110 - val_mae: 1.9528\n",
      "Epoch 125/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 478.5296 - mae: 5.5373 - val_loss: 101.5857 - val_mae: 5.4613\n",
      "Epoch 126/500\n",
      "17037/17037 [==============================] - 42s 2ms/step - loss: 633.5852 - mae: 5.5077 - val_loss: 61.8887 - val_mae: 4.1756\n",
      "Epoch 127/500\n",
      "17037/17037 [==============================] - 40s 2ms/step - loss: 2820.8627 - mae: 5.7134 - val_loss: 58.2153 - val_mae: 3.8522\n",
      "Epoch 128/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1162.3984 - mae: 5.8175 - val_loss: 10.3431 - val_mae: 2.3890\n",
      "Epoch 129/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 781.0127 - mae: 5.9761 - val_loss: 47.0961 - val_mae: 5.5866\n",
      "Epoch 130/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 788.8234 - mae: 5.6933 - val_loss: 59.9927 - val_mae: 3.6000\n",
      "Epoch 131/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 672.2553 - mae: 5.8272 - val_loss: 28.7582 - val_mae: 2.5905\n",
      "Epoch 132/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 442.7818 - mae: 5.5388 - val_loss: 16.8844 - val_mae: 2.1180\n",
      "Epoch 133/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 761.1251 - mae: 5.7162 - val_loss: 36.8914 - val_mae: 3.6037\n",
      "Epoch 134/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 616.7787 - mae: 5.7661 - val_loss: 158.0310 - val_mae: 6.5523\n",
      "Epoch 135/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 599.2572 - mae: 5.7820 - val_loss: 28.2395 - val_mae: 3.2400\n",
      "Epoch 136/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 469.0439 - mae: 5.5005 - val_loss: 85.1594 - val_mae: 4.3749\n",
      "Epoch 137/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 763.2171 - mae: 5.9459 - val_loss: 70.7001 - val_mae: 3.9929\n",
      "Epoch 138/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 734.5980 - mae: 6.1198 - val_loss: 163.4889 - val_mae: 5.5070\n",
      "Epoch 139/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1098.0595 - mae: 6.0267 - val_loss: 157.2477 - val_mae: 6.5157\n",
      "Epoch 140/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1641.2936 - mae: 6.0411 - val_loss: 35.4471 - val_mae: 2.8477\n",
      "Epoch 141/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 547.6353 - mae: 5.4308 - val_loss: 10.7869 - val_mae: 2.2331\n",
      "Epoch 142/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 601.0477 - mae: 6.1486 - val_loss: 88.9521 - val_mae: 4.9088\n",
      "Epoch 143/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 714.0881 - mae: 5.8838 - val_loss: 90.6298 - val_mae: 4.7837\n",
      "Epoch 144/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 545.9100 - mae: 5.9664 - val_loss: 50.3874 - val_mae: 2.8407\n",
      "Epoch 145/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1253.9115 - mae: 5.9399 - val_loss: 42.3119 - val_mae: 2.9116\n",
      "Epoch 146/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1841.2104 - mae: 5.9637 - val_loss: 23.7598 - val_mae: 2.4314\n",
      "Epoch 147/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 537.3809 - mae: 6.0218 - val_loss: 54.5879 - val_mae: 3.6971\n",
      "Epoch 148/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 647.0916 - mae: 6.1381 - val_loss: 101.8608 - val_mae: 4.8230\n",
      "Epoch 149/500\n",
      "17037/17037 [==============================] - 40s 2ms/step - loss: 591.3572 - mae: 5.8831 - val_loss: 14.9369 - val_mae: 2.1603\n",
      "Epoch 150/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 477.5732 - mae: 5.9593 - val_loss: 157.3769 - val_mae: 6.4992\n",
      "Epoch 151/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 440.6666 - mae: 5.8720 - val_loss: 168.8837 - val_mae: 6.8050\n",
      "Epoch 152/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 635.0397 - mae: 5.9703 - val_loss: 72.0707 - val_mae: 3.9693\n",
      "Epoch 153/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 529.2253 - mae: 5.5994 - val_loss: 13.7998 - val_mae: 2.2735\n",
      "Epoch 154/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 654.4979 - mae: 5.6755 - val_loss: 19.6282 - val_mae: 3.6797\n",
      "Epoch 155/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 598.4227 - mae: 5.7609 - val_loss: 157.5388 - val_mae: 6.3099\n",
      "Epoch 156/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 492.2255 - mae: 5.7027 - val_loss: 67.9692 - val_mae: 4.2184\n",
      "Epoch 157/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 610.7599 - mae: 5.5687 - val_loss: 23.9350 - val_mae: 2.7950\n",
      "Epoch 158/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 550.8078 - mae: 5.6311 - val_loss: 22.2335 - val_mae: 2.8882\n",
      "Epoch 159/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 542.0918 - mae: 6.2789 - val_loss: 94.3951 - val_mae: 4.9741\n",
      "Epoch 160/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 839.2927 - mae: 6.1614 - val_loss: 43.5577 - val_mae: 3.1886\n",
      "Epoch 161/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 430.7144 - mae: 5.5581 - val_loss: 96.0469 - val_mae: 4.6204\n",
      "Epoch 162/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 390.5486 - mae: 5.3193 - val_loss: 62.4912 - val_mae: 3.6855\n",
      "Epoch 163/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1064.6180 - mae: 6.0227 - val_loss: 26.9021 - val_mae: 2.9422\n",
      "Epoch 164/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 892.5754 - mae: 6.1922 - val_loss: 62.3487 - val_mae: 3.9647\n",
      "Epoch 165/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1639.8503 - mae: 6.7918 - val_loss: 153.7119 - val_mae: 6.4558\n",
      "Epoch 166/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 456.7790 - mae: 5.9375 - val_loss: 53.8224 - val_mae: 4.0594\n",
      "Epoch 167/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 731.6850 - mae: 5.9115 - val_loss: 20.2153 - val_mae: 2.9985\n",
      "Epoch 168/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 647.3469 - mae: 5.8074 - val_loss: 50.0676 - val_mae: 3.6242\n",
      "Epoch 169/500\n",
      "17037/17037 [==============================] - 38s 2ms/step - loss: 672.7451 - mae: 5.6186 - val_loss: 40.2900 - val_mae: 3.3752\n",
      "Epoch 170/500\n",
      "17037/17037 [==============================] - 42s 2ms/step - loss: 469.4095 - mae: 5.5560 - val_loss: 26.6340 - val_mae: 2.6997\n",
      "Epoch 171/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17037/17037 [==============================] - 39s 2ms/step - loss: 475.5840 - mae: 5.6698 - val_loss: 43.9926 - val_mae: 3.5977\n",
      "Epoch 172/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 791.3073 - mae: 5.7069 - val_loss: 67.1032 - val_mae: 3.8769\n",
      "Epoch 173/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 422.5313 - mae: 5.0496 - val_loss: 124.8505 - val_mae: 5.9049\n",
      "Epoch 174/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 455.9085 - mae: 5.2167 - val_loss: 98.2868 - val_mae: 5.0641\n",
      "Epoch 175/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 489.0799 - mae: 5.1615 - val_loss: 45.1771 - val_mae: 3.0633\n",
      "Epoch 176/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 388.4162 - mae: 5.2486 - val_loss: 51.7551 - val_mae: 2.7939\n",
      "Epoch 177/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 1479.3376 - mae: 5.2845 - val_loss: 11.6978 - val_mae: 2.2176\n",
      "Epoch 178/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 409.8243 - mae: 4.9779 - val_loss: 70.8630 - val_mae: 3.7738\n",
      "Epoch 179/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 634.9600 - mae: 5.1930 - val_loss: 114.9355 - val_mae: 5.4829\n",
      "Epoch 180/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 378.3739 - mae: 5.0614 - val_loss: 109.6243 - val_mae: 5.8381\n",
      "Epoch 181/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 352.1776 - mae: 4.9203 - val_loss: 68.8704 - val_mae: 3.8115\n",
      "Epoch 182/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 673.6891 - mae: 5.0649 - val_loss: 16.6637 - val_mae: 1.9455\n",
      "Epoch 183/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 633.7138 - mae: 4.9889 - val_loss: 51.7141 - val_mae: 3.5383\n",
      "Epoch 184/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 573.6488 - mae: 5.8329 - val_loss: 23.5073 - val_mae: 3.2810\n",
      "Epoch 185/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 405.8773 - mae: 5.0327 - val_loss: 793.6723 - val_mae: 11.1827\n",
      "Epoch 186/500\n",
      "17037/17037 [==============================] - 40s 2ms/step - loss: 533.3367 - mae: 5.3185 - val_loss: 66.2425 - val_mae: 4.0298\n",
      "Epoch 187/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 385.7732 - mae: 5.7338 - val_loss: 79.9636 - val_mae: 4.3687\n",
      "Epoch 188/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 843.9690 - mae: 5.5699 - val_loss: 13.0746 - val_mae: 2.0398\n",
      "Epoch 189/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 408.5496 - mae: 5.2555 - val_loss: 20.1364 - val_mae: 2.3542\n",
      "Epoch 190/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 406.3861 - mae: 5.0803 - val_loss: 24.8621 - val_mae: 3.1560\n",
      "Epoch 191/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 476.1787 - mae: 5.2249 - val_loss: 14.4198 - val_mae: 2.3854\n",
      "Epoch 192/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 373.8715 - mae: 5.2423 - val_loss: 24.9152 - val_mae: 2.4844\n",
      "Epoch 193/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 505.4726 - mae: 5.5045 - val_loss: 58.2267 - val_mae: 3.6726\n",
      "Epoch 194/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 843.6959 - mae: 5.5047 - val_loss: 138.5807 - val_mae: 6.5379\n",
      "Epoch 195/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 866.3529 - mae: 5.6452 - val_loss: 47.0886 - val_mae: 3.7037\n",
      "Epoch 196/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 595.6676 - mae: 5.5453 - val_loss: 97.4460 - val_mae: 4.8334\n",
      "Epoch 197/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 660.2082 - mae: 5.5339 - val_loss: 57.6395 - val_mae: 3.9988\n",
      "Epoch 198/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 781.1005 - mae: 5.6144 - val_loss: 68.1046 - val_mae: 4.0195\n",
      "Epoch 199/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 419.8391 - mae: 5.2724 - val_loss: 120.0670 - val_mae: 5.5615\n",
      "Epoch 200/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 863.6017 - mae: 5.8080 - val_loss: 17.3483 - val_mae: 2.6575\n",
      "Epoch 201/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 482.7266 - mae: 5.7277 - val_loss: 39.1183 - val_mae: 3.1803\n",
      "Epoch 202/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 549.1535 - mae: 5.6557 - val_loss: 157.8060 - val_mae: 6.4604\n",
      "Epoch 203/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 370.7845 - mae: 5.5070 - val_loss: 96.7158 - val_mae: 4.7884\n",
      "Epoch 204/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 889.6569 - mae: 5.5538 - val_loss: 49.8810 - val_mae: 3.5726\n",
      "Epoch 205/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 654.3894 - mae: 5.7874 - val_loss: 70.0692 - val_mae: 3.9462\n",
      "Epoch 206/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 362.9196 - mae: 5.3509 - val_loss: 23.3881 - val_mae: 2.7647\n",
      "Epoch 207/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 388.5887 - mae: 5.2384 - val_loss: 122.7309 - val_mae: 5.2723\n",
      "Epoch 208/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 434.5976 - mae: 5.3214 - val_loss: 13.8282 - val_mae: 2.3883\n",
      "Epoch 209/500\n",
      "17037/17037 [==============================] - 41s 2ms/step - loss: 714.0507 - mae: 5.7471 - val_loss: 39.8160 - val_mae: 3.3869\n",
      "Epoch 210/500\n",
      "17037/17037 [==============================] - 39s 2ms/step - loss: 750.5809 - mae: 6.5417 - val_loss: 15.6532 - val_mae: 2.6034\n",
      "Epoch 211/500\n",
      "17037/17037 [==============================] - 820s 48ms/step - loss: 956.4714 - mae: 5.9610 - val_loss: 43.0270 - val_mae: 3.0866\n",
      "Epoch 212/500\n",
      "17037/17037 [==============================] - 34s 2ms/step - loss: 526.1896 - mae: 5.5795 - val_loss: 10.6134 - val_mae: 2.5539\n",
      "Epoch 213/500\n",
      "17037/17037 [==============================] - 40s 2ms/step - loss: 482.2873 - mae: 5.7139 - val_loss: 50.9582 - val_mae: 3.9173\n",
      "Epoch 214/500\n",
      "17037/17037 [==============================] - 40s 2ms/step - loss: 479.1708 - mae: 5.8184 - val_loss: 76.3114 - val_mae: 4.0763\n",
      "Epoch 215/500\n",
      "17037/17037 [==============================] - 40s 2ms/step - loss: 499.6526 - mae: 5.5702 - val_loss: 42.1345 - val_mae: 3.3074\n",
      "Epoch 216/500\n",
      "17037/17037 [==============================] - 40s 2ms/step - loss: 595.6415 - mae: 5.9637 - val_loss: 56.7620 - val_mae: 3.8851\n",
      "Epoch 217/500\n",
      "17037/17037 [==============================] - 39s 2ms/step - loss: 822.2407 - mae: 5.6591 - val_loss: 66.6796 - val_mae: 5.4373\n",
      "Epoch 218/500\n",
      "17037/17037 [==============================] - 40s 2ms/step - loss: 575.1250 - mae: 5.9227 - val_loss: 13.2472 - val_mae: 2.2738\n",
      "Epoch 219/500\n",
      "17037/17037 [==============================] - 40s 2ms/step - loss: 452.6343 - mae: 5.6294 - val_loss: 144.9797 - val_mae: 6.9332\n",
      "Epoch 220/500\n",
      "17037/17037 [==============================] - 22s 1ms/step - loss: 613.1762 - mae: 5.6789 - val_loss: 76.2836 - val_mae: 4.1198\n",
      "Epoch 221/500\n",
      "17037/17037 [==============================] - 10s 605us/step - loss: 510.7678 - mae: 5.5897 - val_loss: 47.0418 - val_mae: 3.3907\n",
      "Epoch 222/500\n",
      "17037/17037 [==============================] - 10s 572us/step - loss: 480.9675 - mae: 5.6567 - val_loss: 59.7100 - val_mae: 3.8978\n",
      "Epoch 223/500\n",
      "17037/17037 [==============================] - 10s 606us/step - loss: 624.4149 - mae: 5.4328 - val_loss: 23.9658 - val_mae: 2.5021\n",
      "Epoch 224/500\n",
      "17037/17037 [==============================] - 11s 648us/step - loss: 410.5504 - mae: 5.4257 - val_loss: 17.3374 - val_mae: 2.4117\n",
      "Epoch 225/500\n",
      "17037/17037 [==============================] - 11s 666us/step - loss: 392.8370 - mae: 5.2148 - val_loss: 18.8522 - val_mae: 2.3284\n",
      "Epoch 226/500\n",
      "17037/17037 [==============================] - 11s 674us/step - loss: 451.7901 - mae: 5.2480 - val_loss: 15.6101 - val_mae: 2.3370\n",
      "Epoch 227/500\n",
      "17037/17037 [==============================] - 11s 654us/step - loss: 597.5194 - mae: 5.1098 - val_loss: 18.0357 - val_mae: 2.0631\n",
      "Epoch 228/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17037/17037 [==============================] - 12s 684us/step - loss: 469.0518 - mae: 5.2882 - val_loss: 17.1512 - val_mae: 2.0726\n",
      "Epoch 229/500\n",
      "17037/17037 [==============================] - 12s 686us/step - loss: 708.7461 - mae: 5.3952 - val_loss: 45.5347 - val_mae: 3.5393\n",
      "Epoch 230/500\n",
      "17037/17037 [==============================] - 11s 664us/step - loss: 363.5535 - mae: 5.1552 - val_loss: 21.1479 - val_mae: 2.0910\n",
      "Epoch 231/500\n",
      "17037/17037 [==============================] - 12s 684us/step - loss: 404.5944 - mae: 5.1465 - val_loss: 47.3092 - val_mae: 3.5923\n",
      "Epoch 232/500\n",
      "17037/17037 [==============================] - 11s 653us/step - loss: 1468.4804 - mae: 5.1589 - val_loss: 21.7228 - val_mae: 2.1698\n",
      "Epoch 233/500\n",
      "17037/17037 [==============================] - 11s 619us/step - loss: 342.3737 - mae: 5.1753 - val_loss: 70.8097 - val_mae: 4.3736\n",
      "Epoch 234/500\n",
      "17037/17037 [==============================] - 11s 620us/step - loss: 463.5272 - mae: 5.6899 - val_loss: 75.7760 - val_mae: 4.5123\n",
      "Epoch 235/500\n",
      "17037/17037 [==============================] - 11s 631us/step - loss: 496.9456 - mae: 5.8060 - val_loss: 15.7001 - val_mae: 2.5498\n",
      "Epoch 236/500\n",
      "17037/17037 [==============================] - 11s 662us/step - loss: 434.4356 - mae: 5.5720 - val_loss: 68.1334 - val_mae: 3.9726\n",
      "Epoch 237/500\n",
      "17037/17037 [==============================] - 13s 754us/step - loss: 436.7372 - mae: 5.5161 - val_loss: 24.5198 - val_mae: 3.3747\n",
      "Epoch 238/500\n",
      "17037/17037 [==============================] - 13s 736us/step - loss: 532.0467 - mae: 5.6310 - val_loss: 64.7009 - val_mae: 3.7852\n",
      "Epoch 239/500\n",
      "17037/17037 [==============================] - 11s 658us/step - loss: 332.8594 - mae: 5.5040 - val_loss: 186.2259 - val_mae: 6.8020\n",
      "Epoch 240/500\n",
      "17037/17037 [==============================] - 11s 649us/step - loss: 1139.1799 - mae: 6.0078 - val_loss: 92.9363 - val_mae: 4.7853\n",
      "Epoch 241/500\n",
      "17037/17037 [==============================] - 11s 670us/step - loss: 2450.7340 - mae: 5.9352 - val_loss: 74.2091 - val_mae: 4.4089\n",
      "Epoch 242/500\n",
      "17037/17037 [==============================] - 12s 676us/step - loss: 746.5658 - mae: 5.7558 - val_loss: 33.7443 - val_mae: 3.0075\n",
      "Epoch 243/500\n",
      "17037/17037 [==============================] - 11s 640us/step - loss: 520.6225 - mae: 5.8074 - val_loss: 8.0133 - val_mae: 2.1827\n",
      "Epoch 244/500\n",
      "17037/17037 [==============================] - 11s 627us/step - loss: 547.6859 - mae: 5.6339 - val_loss: 28.5305 - val_mae: 3.0807\n",
      "Epoch 245/500\n",
      "17037/17037 [==============================] - 11s 645us/step - loss: 537.0622 - mae: 5.5961 - val_loss: 73.3724 - val_mae: 3.9360\n",
      "Epoch 246/500\n",
      "17037/17037 [==============================] - 11s 628us/step - loss: 871.0534 - mae: 5.8047 - val_loss: 111.2381 - val_mae: 5.4005\n",
      "Epoch 247/500\n",
      "17037/17037 [==============================] - 11s 674us/step - loss: 532.4238 - mae: 5.7493 - val_loss: 44.2948 - val_mae: 3.3212\n",
      "Epoch 248/500\n",
      "17037/17037 [==============================] - 12s 684us/step - loss: 551.2911 - mae: 5.7259 - val_loss: 47.0793 - val_mae: 3.4102\n",
      "Epoch 249/500\n",
      "17037/17037 [==============================] - 11s 659us/step - loss: 361.9291 - mae: 5.7485 - val_loss: 46.1616 - val_mae: 4.7785\n",
      "Epoch 250/500\n",
      "17037/17037 [==============================] - 11s 672us/step - loss: 589.5509 - mae: 5.7936 - val_loss: 59.2031 - val_mae: 3.5020\n",
      "Epoch 251/500\n",
      "17037/17037 [==============================] - 11s 658us/step - loss: 417.1181 - mae: 5.5509 - val_loss: 62.9382 - val_mae: 4.1043\n",
      "Epoch 252/500\n",
      "17037/17037 [==============================] - 12s 730us/step - loss: 530.3936 - mae: 5.5937 - val_loss: 12.9957 - val_mae: 2.7049\n",
      "Epoch 253/500\n",
      "17037/17037 [==============================] - 12s 694us/step - loss: 440.7781 - mae: 5.5424 - val_loss: 25.0541 - val_mae: 2.5744\n",
      "Epoch 254/500\n",
      "17037/17037 [==============================] - 15s 877us/step - loss: 454.3552 - mae: 5.4567 - val_loss: 42.1456 - val_mae: 3.1395\n",
      "Epoch 255/500\n",
      "17037/17037 [==============================] - 12s 716us/step - loss: 432.6855 - mae: 5.4228 - val_loss: 29.3144 - val_mae: 3.0206\n",
      "Epoch 256/500\n",
      "17037/17037 [==============================] - 13s 752us/step - loss: 1087.1207 - mae: 5.4667 - val_loss: 15.4614 - val_mae: 2.4770\n",
      "Epoch 257/500\n",
      "17037/17037 [==============================] - 14s 815us/step - loss: 737.8336 - mae: 5.6961 - val_loss: 144.8810 - val_mae: 6.0264\n",
      "Epoch 258/500\n",
      "17037/17037 [==============================] - 11s 644us/step - loss: 402.3894 - mae: 5.3444 - val_loss: 132.9917 - val_mae: 5.7059\n",
      "Epoch 259/500\n",
      "17037/17037 [==============================] - 12s 677us/step - loss: 423.3645 - mae: 5.3199 - val_loss: 85.5259 - val_mae: 4.5433\n",
      "Epoch 260/500\n",
      "17037/17037 [==============================] - 11s 666us/step - loss: 517.3178 - mae: 5.4758 - val_loss: 79.8276 - val_mae: 4.2907\n",
      "Epoch 261/500\n",
      "17037/17037 [==============================] - 11s 649us/step - loss: 793.8658 - mae: 5.5693 - val_loss: 91.7699 - val_mae: 4.5378\n",
      "Epoch 262/500\n",
      "17037/17037 [==============================] - 12s 716us/step - loss: 431.0637 - mae: 5.2927 - val_loss: 71.5637 - val_mae: 4.5222\n",
      "Epoch 263/500\n",
      "17037/17037 [==============================] - 11s 655us/step - loss: 489.1925 - mae: 5.3575 - val_loss: 41.5943 - val_mae: 3.5951\n",
      "Epoch 264/500\n",
      "17037/17037 [==============================] - 10s 613us/step - loss: 484.9136 - mae: 5.7711 - val_loss: 58.8446 - val_mae: 4.7320\n",
      "Epoch 265/500\n",
      "17037/17037 [==============================] - 11s 631us/step - loss: 548.3469 - mae: 5.5862 - val_loss: 14.7144 - val_mae: 2.3584\n",
      "Epoch 266/500\n",
      "17037/17037 [==============================] - 11s 666us/step - loss: 408.0465 - mae: 5.3482 - val_loss: 16.3659 - val_mae: 2.3191\n",
      "Epoch 267/500\n",
      "17037/17037 [==============================] - 11s 661us/step - loss: 418.6289 - mae: 5.4493 - val_loss: 32.4613 - val_mae: 3.1325\n",
      "Epoch 268/500\n",
      "17037/17037 [==============================] - 11s 659us/step - loss: 496.6720 - mae: 5.1943 - val_loss: 35.7458 - val_mae: 2.7362\n",
      "Epoch 269/500\n",
      "17037/17037 [==============================] - 12s 681us/step - loss: 472.2982 - mae: 5.5076 - val_loss: 14.3555 - val_mae: 1.9073\n",
      "Epoch 270/500\n",
      "17037/17037 [==============================] - 11s 659us/step - loss: 501.7986 - mae: 5.6719 - val_loss: 121.9308 - val_mae: 5.5447\n",
      "Epoch 271/500\n",
      "17037/17037 [==============================] - 12s 687us/step - loss: 640.3193 - mae: 5.3854 - val_loss: 40.1570 - val_mae: 3.3926\n",
      "Epoch 272/500\n",
      "17037/17037 [==============================] - 11s 633us/step - loss: 1013.7369 - mae: 5.5553 - val_loss: 23.6987 - val_mae: 2.6142\n",
      "Epoch 273/500\n",
      "17037/17037 [==============================] - 11s 638us/step - loss: 328.2955 - mae: 5.2263 - val_loss: 51.9226 - val_mae: 3.3911\n",
      "Epoch 274/500\n",
      "17037/17037 [==============================] - 11s 641us/step - loss: 399.3287 - mae: 5.3975 - val_loss: 14.5817 - val_mae: 2.2337\n",
      "Epoch 275/500\n",
      "17037/17037 [==============================] - 12s 681us/step - loss: 591.0145 - mae: 5.5366 - val_loss: 77.4929 - val_mae: 4.3923\n",
      "Epoch 276/500\n",
      "17037/17037 [==============================] - 12s 700us/step - loss: 375.8381 - mae: 5.3668 - val_loss: 45.5140 - val_mae: 3.1368\n",
      "Epoch 277/500\n",
      "17037/17037 [==============================] - 12s 703us/step - loss: 486.5796 - mae: 5.3364 - val_loss: 16.8949 - val_mae: 2.4279\n",
      "Epoch 278/500\n",
      "17037/17037 [==============================] - 13s 735us/step - loss: 496.3854 - mae: 5.4294 - val_loss: 49.7405 - val_mae: 3.2088\n",
      "Epoch 279/500\n",
      "17037/17037 [==============================] - 12s 677us/step - loss: 684.7230 - mae: 5.5797 - val_loss: 23.9020 - val_mae: 2.7413\n",
      "Epoch 280/500\n",
      "17037/17037 [==============================] - 14s 813us/step - loss: 1135.3649 - mae: 5.5248 - val_loss: 52.4493 - val_mae: 3.8522\n",
      "Epoch 281/500\n",
      "17037/17037 [==============================] - 12s 715us/step - loss: 468.4401 - mae: 5.4484 - val_loss: 48.0891 - val_mae: 3.7824\n",
      "Epoch 282/500\n",
      "17037/17037 [==============================] - 11s 617us/step - loss: 476.9799 - mae: 5.3292 - val_loss: 30.4460 - val_mae: 3.1170\n",
      "Epoch 283/500\n",
      "17037/17037 [==============================] - 11s 620us/step - loss: 494.3162 - mae: 5.5148 - val_loss: 91.8136 - val_mae: 4.9025\n",
      "Epoch 284/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17037/17037 [==============================] - 11s 624us/step - loss: 1832.1318 - mae: 5.5150 - val_loss: 58.8011 - val_mae: 3.7659\n",
      "Epoch 285/500\n",
      "17037/17037 [==============================] - 11s 627us/step - loss: 406.0742 - mae: 5.3395 - val_loss: 9.8246 - val_mae: 2.0186\n",
      "Epoch 286/500\n",
      "17037/17037 [==============================] - 11s 624us/step - loss: 381.0804 - mae: 5.2372 - val_loss: 55.9470 - val_mae: 3.4158\n",
      "Epoch 287/500\n",
      "17037/17037 [==============================] - 10s 614us/step - loss: 1194.6574 - mae: 5.1624 - val_loss: 36.1301 - val_mae: 2.7982\n",
      "Epoch 288/500\n",
      "17037/17037 [==============================] - 10s 608us/step - loss: 487.9906 - mae: 5.2412 - val_loss: 71.2955 - val_mae: 4.2605\n",
      "Epoch 289/500\n",
      "17037/17037 [==============================] - 11s 648us/step - loss: 426.1493 - mae: 5.0481 - val_loss: 47.9364 - val_mae: 3.2112\n",
      "Epoch 290/500\n",
      "17037/17037 [==============================] - 12s 679us/step - loss: 497.6029 - mae: 5.2773 - val_loss: 32.4510 - val_mae: 3.3507\n",
      "Epoch 291/500\n",
      "17037/17037 [==============================] - 11s 644us/step - loss: 510.7044 - mae: 5.1887 - val_loss: 66.5633 - val_mae: 3.7754\n",
      "Epoch 292/500\n",
      "17037/17037 [==============================] - 12s 679us/step - loss: 633.6819 - mae: 5.2163 - val_loss: 63.3574 - val_mae: 4.0520\n",
      "Epoch 293/500\n",
      "17037/17037 [==============================] - 10s 613us/step - loss: 401.3798 - mae: 5.3351 - val_loss: 30.3783 - val_mae: 2.9863\n",
      "Epoch 294/500\n",
      "17037/17037 [==============================] - 12s 695us/step - loss: 706.6015 - mae: 5.6295 - val_loss: 75.5430 - val_mae: 4.1318\n",
      "Epoch 295/500\n",
      "17037/17037 [==============================] - 12s 678us/step - loss: 357.9768 - mae: 5.3079 - val_loss: 82.5666 - val_mae: 4.7387\n",
      "Epoch 296/500\n",
      "17037/17037 [==============================] - 13s 734us/step - loss: 830.3760 - mae: 5.4812 - val_loss: 33.7306 - val_mae: 3.2811\n",
      "Epoch 297/500\n",
      "17037/17037 [==============================] - 11s 670us/step - loss: 756.8807 - mae: 5.4628 - val_loss: 44.9683 - val_mae: 3.9155\n",
      "Epoch 298/500\n",
      "17037/17037 [==============================] - 10s 614us/step - loss: 626.6828 - mae: 5.6769 - val_loss: 176.2171 - val_mae: 6.5808\n",
      "Epoch 299/500\n",
      "17037/17037 [==============================] - 10s 610us/step - loss: 549.7565 - mae: 5.4338 - val_loss: 1065.1239 - val_mae: 12.5531\n",
      "Epoch 300/500\n",
      "17037/17037 [==============================] - 11s 644us/step - loss: 371.2552 - mae: 5.3969 - val_loss: 29.4235 - val_mae: 2.7275\n",
      "Epoch 301/500\n",
      "17037/17037 [==============================] - 10s 610us/step - loss: 468.0112 - mae: 5.4583 - val_loss: 47.9005 - val_mae: 3.6659\n",
      "Epoch 302/500\n",
      "17037/17037 [==============================] - 10s 614us/step - loss: 707.4514 - mae: 5.9850 - val_loss: 80.4409 - val_mae: 4.2982\n",
      "Epoch 303/500\n",
      "17037/17037 [==============================] - 10s 614us/step - loss: 343.6374 - mae: 5.1201 - val_loss: 64.1253 - val_mae: 3.6632\n",
      "Epoch 304/500\n",
      "17037/17037 [==============================] - 10s 613us/step - loss: 474.2706 - mae: 5.2201 - val_loss: 54.6718 - val_mae: 4.1515\n",
      "Epoch 305/500\n",
      "17037/17037 [==============================] - 10s 615us/step - loss: 336.3796 - mae: 5.2310 - val_loss: 52.8221 - val_mae: 3.8969\n",
      "Epoch 306/500\n",
      "17037/17037 [==============================] - 10s 613us/step - loss: 377.2264 - mae: 5.2263 - val_loss: 21.6220 - val_mae: 2.6397\n",
      "Epoch 307/500\n",
      "17037/17037 [==============================] - 11s 616us/step - loss: 824.3239 - mae: 5.1833 - val_loss: 61.1924 - val_mae: 4.5773\n",
      "Epoch 308/500\n",
      "17037/17037 [==============================] - 10s 612us/step - loss: 415.8763 - mae: 5.4021 - val_loss: 29.5532 - val_mae: 3.6577\n",
      "Epoch 309/500\n",
      "17037/17037 [==============================] - 10s 610us/step - loss: 558.7451 - mae: 5.3190 - val_loss: 60.5673 - val_mae: 3.9814\n",
      "Epoch 310/500\n",
      "17037/17037 [==============================] - 10s 614us/step - loss: 592.7437 - mae: 5.8038 - val_loss: 169.0015 - val_mae: 6.5571\n",
      "Epoch 311/500\n",
      "17037/17037 [==============================] - 11s 627us/step - loss: 400.5132 - mae: 5.5194 - val_loss: 60.1801 - val_mae: 4.1225\n",
      "Epoch 312/500\n",
      "17037/17037 [==============================] - 10s 610us/step - loss: 541.1021 - mae: 5.5898 - val_loss: 35.9883 - val_mae: 3.5999\n",
      "Epoch 313/500\n",
      "17037/17037 [==============================] - 11s 631us/step - loss: 791.4438 - mae: 5.1109 - val_loss: 33.5001 - val_mae: 3.2031\n",
      "Epoch 314/500\n",
      "17037/17037 [==============================] - 11s 623us/step - loss: 314.7116 - mae: 4.9167 - val_loss: 665.1196 - val_mae: 9.1758\n",
      "Epoch 315/500\n",
      "17037/17037 [==============================] - 10s 612us/step - loss: 354.5318 - mae: 4.9500 - val_loss: 2508.1479 - val_mae: 16.4060\n",
      "Epoch 316/500\n",
      "17037/17037 [==============================] - 10s 615us/step - loss: 488.8503 - mae: 4.9402 - val_loss: 75.1957 - val_mae: 4.4825\n",
      "Epoch 317/500\n",
      "17037/17037 [==============================] - 11s 619us/step - loss: 355.9614 - mae: 4.8363 - val_loss: 5.2860 - val_mae: 1.6171\n",
      "Epoch 318/500\n",
      "17037/17037 [==============================] - 10s 608us/step - loss: 295.8599 - mae: 4.6334 - val_loss: 33.5763 - val_mae: 2.8216\n",
      "Epoch 319/500\n",
      "17037/17037 [==============================] - 10s 612us/step - loss: 324.8972 - mae: 4.6167 - val_loss: 21.1032 - val_mae: 2.4750\n",
      "Epoch 320/500\n",
      "17037/17037 [==============================] - 10s 608us/step - loss: 276.1856 - mae: 4.4219 - val_loss: 7.6666 - val_mae: 1.7095\n",
      "Epoch 321/500\n",
      "17037/17037 [==============================] - 10s 608us/step - loss: 280.4262 - mae: 4.1842 - val_loss: 7.6018 - val_mae: 1.5289\n",
      "Epoch 322/500\n",
      "17037/17037 [==============================] - 10s 610us/step - loss: 256.5605 - mae: 4.1872 - val_loss: 45.8075 - val_mae: 3.4408\n",
      "Epoch 323/500\n",
      "17037/17037 [==============================] - 10s 612us/step - loss: 262.1928 - mae: 4.1979 - val_loss: 4.4094 - val_mae: 1.5367\n",
      "Epoch 324/500\n",
      "17037/17037 [==============================] - 10s 610us/step - loss: 195.6824 - mae: 3.9470 - val_loss: 4.5080 - val_mae: 1.2731\n",
      "Epoch 325/500\n",
      "17037/17037 [==============================] - 11s 629us/step - loss: 237.4105 - mae: 3.9528 - val_loss: 3.6825 - val_mae: 1.4740\n",
      "Epoch 326/500\n",
      "17037/17037 [==============================] - 10s 614us/step - loss: 319.4166 - mae: 4.0346 - val_loss: 7.7854 - val_mae: 1.4444\n",
      "Epoch 327/500\n",
      "17037/17037 [==============================] - 10s 614us/step - loss: 232.2946 - mae: 3.9835 - val_loss: 16.6933 - val_mae: 2.1608\n",
      "Epoch 328/500\n",
      "17037/17037 [==============================] - 9s 507us/step - loss: 262.1748 - mae: 4.1194 - val_loss: 9.2109 - val_mae: 1.5966\n",
      "Epoch 329/500\n",
      "17037/17037 [==============================] - 8s 481us/step - loss: 247.2216 - mae: 3.9693 - val_loss: 1992.3341 - val_mae: 13.9391\n",
      "Epoch 330/500\n",
      "17037/17037 [==============================] - 8s 476us/step - loss: 319.6161 - mae: 4.2108 - val_loss: 31.9951 - val_mae: 2.8275\n",
      "Epoch 331/500\n",
      "17037/17037 [==============================] - 8s 478us/step - loss: 224.1564 - mae: 4.0234 - val_loss: 8.0565 - val_mae: 2.0711\n",
      "Epoch 332/500\n",
      "17037/17037 [==============================] - 8s 474us/step - loss: 309.3735 - mae: 4.1331 - val_loss: 86.3197 - val_mae: 4.5433\n",
      "Epoch 333/500\n",
      "17037/17037 [==============================] - 8s 477us/step - loss: 212.7236 - mae: 4.0747 - val_loss: 13.8091 - val_mae: 1.9618\n",
      "Epoch 334/500\n",
      "17037/17037 [==============================] - 8s 480us/step - loss: 196.5366 - mae: 3.9607 - val_loss: 9.1713 - val_mae: 1.5845\n",
      "Epoch 335/500\n",
      "17037/17037 [==============================] - 8s 476us/step - loss: 338.8059 - mae: 3.9704 - val_loss: 7.4485 - val_mae: 1.5145\n",
      "Epoch 336/500\n",
      "17037/17037 [==============================] - 8s 481us/step - loss: 265.4250 - mae: 4.0459 - val_loss: 86.8383 - val_mae: 4.0427\n",
      "Epoch 337/500\n",
      "17037/17037 [==============================] - 8s 477us/step - loss: 288.7585 - mae: 4.0855 - val_loss: 24.3348 - val_mae: 2.8685\n",
      "Epoch 338/500\n",
      "17037/17037 [==============================] - 9s 533us/step - loss: 288.8153 - mae: 4.5550 - val_loss: 42.1014 - val_mae: 3.0400\n",
      "Epoch 339/500\n",
      "17037/17037 [==============================] - 9s 515us/step - loss: 453.0601 - mae: 4.2851 - val_loss: 72.0988 - val_mae: 4.0209\n",
      "Epoch 340/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17037/17037 [==============================] - 8s 477us/step - loss: 275.3338 - mae: 4.4708 - val_loss: 6.3507 - val_mae: 1.9430\n",
      "Epoch 341/500\n",
      "17037/17037 [==============================] - 8s 474us/step - loss: 424.2240 - mae: 4.6589 - val_loss: 25.2117 - val_mae: 2.7367\n",
      "Epoch 342/500\n",
      "17037/17037 [==============================] - 8s 476us/step - loss: 750.2309 - mae: 4.5043 - val_loss: 3.0652 - val_mae: 1.3687\n",
      "Epoch 343/500\n",
      "17037/17037 [==============================] - 8s 483us/step - loss: 294.5219 - mae: 4.4143 - val_loss: 58.1402 - val_mae: 3.6324\n",
      "Epoch 344/500\n",
      "17037/17037 [==============================] - 8s 483us/step - loss: 342.3488 - mae: 4.5132 - val_loss: 19.0437 - val_mae: 2.2429\n",
      "Epoch 345/500\n",
      "17037/17037 [==============================] - 8s 480us/step - loss: 372.5833 - mae: 4.2804 - val_loss: 36.6298 - val_mae: 2.7224\n",
      "Epoch 346/500\n",
      "17037/17037 [==============================] - 8s 479us/step - loss: 365.0480 - mae: 4.5287 - val_loss: 54.2772 - val_mae: 4.0566\n",
      "Epoch 347/500\n",
      "17037/17037 [==============================] - 8s 482us/step - loss: 263.6828 - mae: 4.3962 - val_loss: 24.0379 - val_mae: 2.4447\n",
      "Epoch 348/500\n",
      "17037/17037 [==============================] - 8s 478us/step - loss: 397.2389 - mae: 4.5330 - val_loss: 36.8741 - val_mae: 2.8341\n",
      "Epoch 349/500\n",
      "17037/17037 [==============================] - 8s 478us/step - loss: 380.6618 - mae: 4.4772 - val_loss: 2.6622 - val_mae: 1.3175\n",
      "Epoch 350/500\n",
      "17037/17037 [==============================] - 8s 479us/step - loss: 297.5743 - mae: 4.4588 - val_loss: 6.5861 - val_mae: 1.8096\n",
      "Epoch 351/500\n",
      "17037/17037 [==============================] - 8s 477us/step - loss: 289.9046 - mae: 4.5251 - val_loss: 73.0231 - val_mae: 4.3135\n",
      "Epoch 352/500\n",
      "17037/17037 [==============================] - 8s 477us/step - loss: 257.1579 - mae: 4.4422 - val_loss: 66.4699 - val_mae: 4.0811\n",
      "Epoch 353/500\n",
      "17037/17037 [==============================] - 8s 482us/step - loss: 366.6922 - mae: 4.5204 - val_loss: 107.3170 - val_mae: 5.6198\n",
      "Epoch 354/500\n",
      "17037/17037 [==============================] - 8s 480us/step - loss: 387.1172 - mae: 4.5463 - val_loss: 69.6897 - val_mae: 4.2497\n",
      "Epoch 355/500\n",
      "17037/17037 [==============================] - 8s 477us/step - loss: 301.9863 - mae: 4.6550 - val_loss: 39.3718 - val_mae: 3.1874\n",
      "Epoch 356/500\n",
      "17037/17037 [==============================] - 8s 481us/step - loss: 379.8547 - mae: 4.3800 - val_loss: 10.9449 - val_mae: 1.6375\n",
      "Epoch 357/500\n",
      "17037/17037 [==============================] - 8s 478us/step - loss: 445.5044 - mae: 4.3387 - val_loss: 73.2802 - val_mae: 4.3397\n",
      "Epoch 358/500\n",
      "17037/17037 [==============================] - 8s 483us/step - loss: 385.8708 - mae: 4.5025 - val_loss: 62.1574 - val_mae: 4.1654\n",
      "Epoch 359/500\n",
      "17037/17037 [==============================] - 8s 476us/step - loss: 454.6005 - mae: 4.5441 - val_loss: 9.6066 - val_mae: 1.7308\n",
      "Epoch 360/500\n",
      "17037/17037 [==============================] - 8s 484us/step - loss: 331.8344 - mae: 4.3417 - val_loss: 23.7224 - val_mae: 2.2650\n",
      "Epoch 361/500\n",
      "17037/17037 [==============================] - 8s 487us/step - loss: 384.4236 - mae: 4.4157 - val_loss: 97.2655 - val_mae: 4.8689\n",
      "Epoch 362/500\n",
      "17037/17037 [==============================] - 8s 477us/step - loss: 308.5379 - mae: 4.3925 - val_loss: 3.3124 - val_mae: 1.1903\n",
      "Epoch 363/500\n",
      "17037/17037 [==============================] - 8s 478us/step - loss: 312.7676 - mae: 4.3988 - val_loss: 53.9340 - val_mae: 3.5367\n",
      "Epoch 364/500\n",
      "17037/17037 [==============================] - 8s 484us/step - loss: 351.2605 - mae: 4.3737 - val_loss: 53.3778 - val_mae: 3.3216\n",
      "Epoch 365/500\n",
      "17037/17037 [==============================] - 8s 477us/step - loss: 214.5043 - mae: 4.0492 - val_loss: 91.3457 - val_mae: 4.9045\n",
      "Epoch 366/500\n",
      "17037/17037 [==============================] - 8s 480us/step - loss: 247.0522 - mae: 4.2118 - val_loss: 44.6334 - val_mae: 3.4791\n",
      "Epoch 367/500\n",
      "17037/17037 [==============================] - 8s 478us/step - loss: 477.9879 - mae: 4.3427 - val_loss: 55.5823 - val_mae: 4.2875\n",
      "Epoch 368/500\n",
      "17037/17037 [==============================] - 8s 474us/step - loss: 575.5374 - mae: 4.2255 - val_loss: 15.3342 - val_mae: 2.2072\n",
      "Epoch 369/500\n",
      "17037/17037 [==============================] - 8s 493us/step - loss: 292.8875 - mae: 4.2677 - val_loss: 38.1804 - val_mae: 3.2379\n",
      "Epoch 370/500\n",
      "17037/17037 [==============================] - 8s 494us/step - loss: 316.6089 - mae: 4.1863 - val_loss: 19.4515 - val_mae: 1.9933\n",
      "Epoch 371/500\n",
      "17037/17037 [==============================] - 10s 599us/step - loss: 200.7118 - mae: 4.1276 - val_loss: 16.2438 - val_mae: 2.3551\n",
      "Epoch 372/500\n",
      "17037/17037 [==============================] - 10s 577us/step - loss: 223.7141 - mae: 4.1043 - val_loss: 16.4663 - val_mae: 2.4966\n",
      "Epoch 373/500\n",
      "17037/17037 [==============================] - 9s 523us/step - loss: 256.4969 - mae: 4.0693 - val_loss: 7.5923 - val_mae: 1.6351\n",
      "Epoch 374/500\n",
      "17037/17037 [==============================] - 10s 564us/step - loss: 250.5514 - mae: 4.0079 - val_loss: 26.9703 - val_mae: 2.4262\n",
      "Epoch 375/500\n",
      "17037/17037 [==============================] - 9s 524us/step - loss: 1444.2525 - mae: 4.3798 - val_loss: 65.6602 - val_mae: 3.9484\n",
      "Epoch 376/500\n",
      "17037/17037 [==============================] - 8s 482us/step - loss: 228.4202 - mae: 4.1195 - val_loss: 17.3146 - val_mae: 2.1869\n",
      "Epoch 377/500\n",
      "17037/17037 [==============================] - 8s 483us/step - loss: 314.7870 - mae: 4.0686 - val_loss: 10.3083 - val_mae: 2.0146\n",
      "Epoch 378/500\n",
      "17037/17037 [==============================] - 8s 480us/step - loss: 490.5823 - mae: 4.0915 - val_loss: 106.6672 - val_mae: 5.2252\n",
      "Epoch 379/500\n",
      "17037/17037 [==============================] - 8s 483us/step - loss: 376.2139 - mae: 4.3790 - val_loss: 12.7406 - val_mae: 1.9532\n",
      "Epoch 380/500\n",
      "17037/17037 [==============================] - 8s 478us/step - loss: 282.3699 - mae: 4.1933 - val_loss: 20.8824 - val_mae: 1.9568\n",
      "Epoch 381/500\n",
      "17037/17037 [==============================] - 8s 477us/step - loss: 233.9477 - mae: 4.1603 - val_loss: 50.4368 - val_mae: 3.6910\n",
      "Epoch 382/500\n",
      "17037/17037 [==============================] - 8s 480us/step - loss: 301.6912 - mae: 4.2480 - val_loss: 224.4287 - val_mae: 6.9457\n",
      "Epoch 383/500\n",
      "17037/17037 [==============================] - 8s 480us/step - loss: 312.5228 - mae: 4.3412 - val_loss: 10.4042 - val_mae: 1.8906\n",
      "Epoch 384/500\n",
      "17037/17037 [==============================] - 8s 476us/step - loss: 333.2180 - mae: 4.3422 - val_loss: 74.8117 - val_mae: 4.2002\n",
      "Epoch 385/500\n",
      "17037/17037 [==============================] - 8s 478us/step - loss: 293.0710 - mae: 4.3739 - val_loss: 22.4486 - val_mae: 2.3625\n",
      "Epoch 386/500\n",
      "17037/17037 [==============================] - 8s 488us/step - loss: 373.8299 - mae: 4.5765 - val_loss: 32.0194 - val_mae: 2.7573\n",
      "Epoch 387/500\n",
      "17037/17037 [==============================] - 8s 497us/step - loss: 489.0337 - mae: 4.2407 - val_loss: 19.8461 - val_mae: 2.3297\n",
      "Epoch 388/500\n",
      "17037/17037 [==============================] - 8s 480us/step - loss: 501.6666 - mae: 4.3510 - val_loss: 69.7231 - val_mae: 4.1956\n",
      "Epoch 389/500\n",
      "17037/17037 [==============================] - 8s 476us/step - loss: 225.5496 - mae: 4.4223 - val_loss: 28.5736 - val_mae: 3.0099\n",
      "Epoch 390/500\n",
      "17037/17037 [==============================] - 8s 477us/step - loss: 210.9694 - mae: 4.7826 - val_loss: 6.6773 - val_mae: 1.3803\n",
      "Epoch 391/500\n",
      "17037/17037 [==============================] - 8s 474us/step - loss: 1001.6622 - mae: 4.5887 - val_loss: 48.0601 - val_mae: 3.7697\n",
      "Epoch 392/500\n",
      "17037/17037 [==============================] - 8s 475us/step - loss: 279.0831 - mae: 4.5350 - val_loss: 72.1436 - val_mae: 3.9316\n",
      "Epoch 393/500\n",
      "17037/17037 [==============================] - 8s 476us/step - loss: 268.1358 - mae: 4.3642 - val_loss: 41.1904 - val_mae: 2.9515\n",
      "Epoch 394/500\n",
      "17037/17037 [==============================] - 8s 485us/step - loss: 232.2173 - mae: 4.4199 - val_loss: 20.3103 - val_mae: 2.3270\n",
      "Epoch 395/500\n",
      "17037/17037 [==============================] - 8s 478us/step - loss: 365.0148 - mae: 4.4648 - val_loss: 27.6465 - val_mae: 2.2047\n",
      "Epoch 396/500\n",
      "17037/17037 [==============================] - 8s 478us/step - loss: 240.1665 - mae: 4.4896 - val_loss: 102.2300 - val_mae: 5.1771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397/500\n",
      "17037/17037 [==============================] - 8s 480us/step - loss: 360.4690 - mae: 4.4347 - val_loss: 16.8591 - val_mae: 2.0335\n",
      "Epoch 398/500\n",
      "17037/17037 [==============================] - 8s 477us/step - loss: 344.7518 - mae: 4.4321 - val_loss: 18.7900 - val_mae: 3.0077\n",
      "Epoch 399/500\n",
      "17037/17037 [==============================] - 8s 475us/step - loss: 221.1413 - mae: 4.4344 - val_loss: 156.2854 - val_mae: 6.2834\n",
      "Epoch 400/500\n",
      "17037/17037 [==============================] - 9s 535us/step - loss: 567.7038 - mae: 4.4651 - val_loss: 18.6127 - val_mae: 1.9704\n",
      "Epoch 401/500\n",
      "17037/17037 [==============================] - 10s 608us/step - loss: 273.8927 - mae: 4.4261 - val_loss: 50.3903 - val_mae: 2.8569\n",
      "Epoch 402/500\n",
      "17037/17037 [==============================] - 8s 481us/step - loss: 363.3346 - mae: 4.4245 - val_loss: 15.2154 - val_mae: 2.3223\n",
      "Epoch 403/500\n",
      "17037/17037 [==============================] - 8s 480us/step - loss: 310.8446 - mae: 4.3723 - val_loss: 31.4596 - val_mae: 2.3394\n",
      "Epoch 404/500\n",
      "17037/17037 [==============================] - 9s 509us/step - loss: 287.6055 - mae: 4.2693 - val_loss: 63.4076 - val_mae: 3.9666\n",
      "Epoch 405/500\n",
      "17037/17037 [==============================] - 8s 491us/step - loss: 242.5866 - mae: 4.3111 - val_loss: 22.1679 - val_mae: 1.9955\n",
      "Epoch 406/500\n",
      "17037/17037 [==============================] - 8s 493us/step - loss: 477.4813 - mae: 4.3602 - val_loss: 25.2983 - val_mae: 2.2299\n",
      "Epoch 407/500\n",
      "17037/17037 [==============================] - 8s 492us/step - loss: 260.4833 - mae: 4.4554 - val_loss: 142.4508 - val_mae: 5.6794\n",
      "Epoch 408/500\n",
      "17037/17037 [==============================] - 8s 491us/step - loss: 299.1788 - mae: 4.6856 - val_loss: 31.3265 - val_mae: 2.5102\n",
      "Epoch 409/500\n",
      "17037/17037 [==============================] - 8s 490us/step - loss: 365.3353 - mae: 4.8601 - val_loss: 43.2431 - val_mae: 3.2030\n",
      "Epoch 410/500\n",
      "17037/17037 [==============================] - 8s 492us/step - loss: 388.2589 - mae: 4.8226 - val_loss: 75.9535 - val_mae: 3.8429\n",
      "Epoch 411/500\n",
      "17037/17037 [==============================] - 8s 495us/step - loss: 394.1350 - mae: 4.8623 - val_loss: 39.1843 - val_mae: 3.1626\n",
      "Epoch 412/500\n",
      "17037/17037 [==============================] - 9s 500us/step - loss: 279.7782 - mae: 4.8043 - val_loss: 72.3780 - val_mae: 3.8805\n",
      "Epoch 413/500\n",
      "17037/17037 [==============================] - 8s 490us/step - loss: 283.6615 - mae: 4.6596 - val_loss: 63.1552 - val_mae: 3.7773\n",
      "Epoch 414/500\n",
      "17037/17037 [==============================] - 8s 492us/step - loss: 262.9380 - mae: 4.2494 - val_loss: 17.0711 - val_mae: 2.0515\n",
      "Epoch 415/500\n",
      "17037/17037 [==============================] - 9s 500us/step - loss: 291.3415 - mae: 4.1604 - val_loss: 32.8651 - val_mae: 2.7007\n",
      "Epoch 416/500\n",
      "17037/17037 [==============================] - 8s 495us/step - loss: 271.4706 - mae: 4.1510 - val_loss: 34.8298 - val_mae: 2.7789\n",
      "Epoch 417/500\n",
      "17037/17037 [==============================] - 8s 490us/step - loss: 238.6871 - mae: 4.0327 - val_loss: 9.6237 - val_mae: 1.5649\n",
      "Epoch 418/500\n",
      "17037/17037 [==============================] - 8s 490us/step - loss: 387.5543 - mae: 4.2580 - val_loss: 31.7851 - val_mae: 3.2160\n",
      "Epoch 419/500\n",
      "17037/17037 [==============================] - 8s 493us/step - loss: 233.4223 - mae: 4.1389 - val_loss: 34.9154 - val_mae: 3.2684\n",
      "Epoch 420/500\n",
      "17037/17037 [==============================] - 8s 489us/step - loss: 269.3964 - mae: 4.1084 - val_loss: 12.2709 - val_mae: 2.1641\n",
      "Epoch 421/500\n",
      "17037/17037 [==============================] - 8s 491us/step - loss: 464.5762 - mae: 4.1056 - val_loss: 53.3705 - val_mae: 3.2865\n",
      "Epoch 422/500\n",
      "17037/17037 [==============================] - 9s 509us/step - loss: 248.7067 - mae: 4.0515 - val_loss: 66.5991 - val_mae: 4.1845\n",
      "Epoch 423/500\n",
      "17037/17037 [==============================] - 9s 512us/step - loss: 208.6322 - mae: 4.0017 - val_loss: 23.7490 - val_mae: 2.5323\n",
      "Epoch 424/500\n",
      "17037/17037 [==============================] - 9s 522us/step - loss: 221.1415 - mae: 3.9982 - val_loss: 2.9928 - val_mae: 0.9466\n",
      "Epoch 425/500\n",
      "17037/17037 [==============================] - 9s 502us/step - loss: 203.0887 - mae: 3.9924 - val_loss: 60.6669 - val_mae: 3.7785\n",
      "Epoch 426/500\n",
      "17037/17037 [==============================] - 9s 522us/step - loss: 206.4878 - mae: 3.9681 - val_loss: 20.1785 - val_mae: 2.7957\n",
      "Epoch 427/500\n",
      "17037/17037 [==============================] - 8s 492us/step - loss: 257.3483 - mae: 4.0759 - val_loss: 25.2872 - val_mae: 2.6130\n",
      "Epoch 428/500\n",
      "17037/17037 [==============================] - 9s 500us/step - loss: 233.2379 - mae: 4.0203 - val_loss: 33.9796 - val_mae: 2.7201\n",
      "Epoch 429/500\n",
      "17037/17037 [==============================] - 8s 498us/step - loss: 251.5721 - mae: 3.8625 - val_loss: 22.7053 - val_mae: 2.3337\n",
      "Epoch 430/500\n",
      "17037/17037 [==============================] - 8s 489us/step - loss: 271.3608 - mae: 3.9442 - val_loss: 20.0638 - val_mae: 2.0235\n",
      "Epoch 431/500\n",
      "17037/17037 [==============================] - 8s 490us/step - loss: 267.6935 - mae: 3.9914 - val_loss: 17.1240 - val_mae: 1.8673\n",
      "Epoch 432/500\n",
      "17037/17037 [==============================] - 9s 507us/step - loss: 383.9654 - mae: 3.9701 - val_loss: 22.2231 - val_mae: 2.3985\n",
      "Epoch 433/500\n",
      "17037/17037 [==============================] - 9s 508us/step - loss: 196.6966 - mae: 3.8218 - val_loss: 13.9675 - val_mae: 1.7467\n",
      "Epoch 434/500\n",
      "17037/17037 [==============================] - 8s 496us/step - loss: 514.2973 - mae: 3.9643 - val_loss: 29.5085 - val_mae: 2.5323\n",
      "Epoch 435/500\n",
      "17037/17037 [==============================] - 9s 548us/step - loss: 241.6603 - mae: 3.8457 - val_loss: 3.6557 - val_mae: 1.0222\n",
      "Epoch 436/500\n",
      "17037/17037 [==============================] - 8s 495us/step - loss: 314.3543 - mae: 3.8398 - val_loss: 28.9539 - val_mae: 2.4856\n",
      "Epoch 437/500\n",
      "17037/17037 [==============================] - 8s 496us/step - loss: 285.1983 - mae: 3.8729 - val_loss: 18.8523 - val_mae: 2.3967\n",
      "Epoch 438/500\n",
      "17037/17037 [==============================] - 9s 499us/step - loss: 209.7438 - mae: 3.9279 - val_loss: 2.6440 - val_mae: 1.0031\n",
      "Epoch 439/500\n",
      "17037/17037 [==============================] - 8s 499us/step - loss: 297.7861 - mae: 3.8815 - val_loss: 1.6478 - val_mae: 0.8968\n",
      "Epoch 440/500\n",
      "17037/17037 [==============================] - 8s 494us/step - loss: 238.2729 - mae: 3.8620 - val_loss: 50.6489 - val_mae: 4.1192\n",
      "Epoch 441/500\n",
      "17037/17037 [==============================] - 9s 512us/step - loss: 214.6009 - mae: 3.8458 - val_loss: 221.4005 - val_mae: 7.0370\n",
      "Epoch 442/500\n",
      "17037/17037 [==============================] - 9s 505us/step - loss: 449.1628 - mae: 3.9466 - val_loss: 42.0944 - val_mae: 2.8488\n",
      "Epoch 443/500\n",
      "17037/17037 [==============================] - 9s 511us/step - loss: 199.8418 - mae: 3.7970 - val_loss: 13.1285 - val_mae: 1.8675\n",
      "Epoch 444/500\n",
      "17037/17037 [==============================] - 9s 510us/step - loss: 224.5548 - mae: 3.8196 - val_loss: 2.2762 - val_mae: 1.0073\n",
      "Epoch 445/500\n",
      "17037/17037 [==============================] - 9s 505us/step - loss: 216.9322 - mae: 3.7954 - val_loss: 23.5591 - val_mae: 2.4592\n",
      "Epoch 446/500\n",
      "17037/17037 [==============================] - 8s 497us/step - loss: 251.4839 - mae: 3.8988 - val_loss: 90.6558 - val_mae: 5.0791\n",
      "Epoch 447/500\n",
      "17037/17037 [==============================] - 9s 503us/step - loss: 213.8610 - mae: 3.7875 - val_loss: 193.8418 - val_mae: 6.7927\n",
      "Epoch 448/500\n",
      "17037/17037 [==============================] - 9s 500us/step - loss: 232.1906 - mae: 3.8419 - val_loss: 8.4285 - val_mae: 1.7817\n",
      "Epoch 449/500\n",
      "17037/17037 [==============================] - 9s 511us/step - loss: 220.0228 - mae: 3.8207 - val_loss: 48.7439 - val_mae: 3.5167\n",
      "Epoch 450/500\n",
      "17037/17037 [==============================] - 9s 499us/step - loss: 207.2361 - mae: 3.7989 - val_loss: 18.7701 - val_mae: 2.3044\n",
      "Epoch 451/500\n",
      "17037/17037 [==============================] - 9s 506us/step - loss: 202.4327 - mae: 3.8302 - val_loss: 65.5991 - val_mae: 4.0188\n",
      "Epoch 452/500\n",
      "17037/17037 [==============================] - 9s 499us/step - loss: 218.7024 - mae: 3.7626 - val_loss: 34.7149 - val_mae: 2.8288\n",
      "Epoch 453/500\n",
      "17037/17037 [==============================] - 9s 499us/step - loss: 257.9716 - mae: 3.7498 - val_loss: 23.6934 - val_mae: 2.3283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454/500\n",
      "17037/17037 [==============================] - 8s 496us/step - loss: 253.5825 - mae: 3.8073 - val_loss: 36.5191 - val_mae: 2.7373\n",
      "Epoch 455/500\n",
      "17037/17037 [==============================] - 8s 495us/step - loss: 426.4590 - mae: 3.8816 - val_loss: 15.3517 - val_mae: 2.0294\n",
      "Epoch 456/500\n",
      "17037/17037 [==============================] - 8s 492us/step - loss: 283.4444 - mae: 3.8068 - val_loss: 1058.6489 - val_mae: 14.1154\n",
      "Epoch 457/500\n",
      "17037/17037 [==============================] - 9s 507us/step - loss: 296.7223 - mae: 3.8985 - val_loss: 29.8406 - val_mae: 2.3982\n",
      "Epoch 458/500\n",
      "17037/17037 [==============================] - 8s 496us/step - loss: 289.1325 - mae: 3.7529 - val_loss: 99.6400 - val_mae: 4.3946\n",
      "Epoch 459/500\n",
      "17037/17037 [==============================] - 9s 528us/step - loss: 239.7069 - mae: 3.7963 - val_loss: 22.5932 - val_mae: 2.1203\n",
      "Epoch 460/500\n",
      "17037/17037 [==============================] - 9s 502us/step - loss: 335.2156 - mae: 3.8943 - val_loss: 26.3319 - val_mae: 2.2987\n",
      "Epoch 461/500\n",
      "17037/17037 [==============================] - 9s 535us/step - loss: 225.5236 - mae: 3.6399 - val_loss: 9.3670 - val_mae: 1.8711\n",
      "Epoch 462/500\n",
      "17037/17037 [==============================] - 11s 632us/step - loss: 178.1055 - mae: 3.6768 - val_loss: 54.7315 - val_mae: 3.2960\n",
      "Epoch 463/500\n",
      "17037/17037 [==============================] - 9s 533us/step - loss: 533.3279 - mae: 3.7392 - val_loss: 13.7547 - val_mae: 1.9099\n",
      "Epoch 464/500\n",
      "17037/17037 [==============================] - 8s 479us/step - loss: 386.4790 - mae: 3.7562 - val_loss: 4.3682 - val_mae: 1.1894\n",
      "Epoch 465/500\n",
      "17037/17037 [==============================] - 8s 475us/step - loss: 193.2779 - mae: 3.6584 - val_loss: 56.7592 - val_mae: 4.0625\n",
      "Epoch 466/500\n",
      "17037/17037 [==============================] - 8s 492us/step - loss: 349.1726 - mae: 3.8092 - val_loss: 54.8567 - val_mae: 3.9804\n",
      "Epoch 467/500\n",
      "17037/17037 [==============================] - 8s 490us/step - loss: 251.6348 - mae: 3.7508 - val_loss: 7.9497 - val_mae: 1.6870\n",
      "Epoch 468/500\n",
      "17037/17037 [==============================] - 8s 488us/step - loss: 181.3000 - mae: 3.6408 - val_loss: 8.8384 - val_mae: 1.5395\n",
      "Epoch 469/500\n",
      "17037/17037 [==============================] - 8s 483us/step - loss: 212.3904 - mae: 3.6863 - val_loss: 8.1118 - val_mae: 2.0627\n",
      "Epoch 470/500\n",
      "17037/17037 [==============================] - 8s 479us/step - loss: 184.4782 - mae: 3.7430 - val_loss: 32.0700 - val_mae: 2.6800\n",
      "Epoch 471/500\n",
      "17037/17037 [==============================] - 8s 492us/step - loss: 304.5521 - mae: 3.8506 - val_loss: 17.8627 - val_mae: 1.9088\n",
      "Epoch 472/500\n",
      "17037/17037 [==============================] - 8s 487us/step - loss: 202.5918 - mae: 3.7300 - val_loss: 59.8602 - val_mae: 3.7640\n",
      "Epoch 473/500\n",
      "17037/17037 [==============================] - 8s 479us/step - loss: 256.3458 - mae: 3.6247 - val_loss: 25.8291 - val_mae: 2.5603\n",
      "Epoch 474/500\n",
      "17037/17037 [==============================] - 8s 495us/step - loss: 249.1651 - mae: 3.7023 - val_loss: 5.1023 - val_mae: 1.3685\n",
      "Epoch 475/500\n",
      "17037/17037 [==============================] - 8s 483us/step - loss: 224.4377 - mae: 3.7207 - val_loss: 38.9625 - val_mae: 2.8048\n",
      "Epoch 476/500\n",
      "17037/17037 [==============================] - 8s 487us/step - loss: 183.4126 - mae: 3.6533 - val_loss: 9.6746 - val_mae: 1.4033\n",
      "Epoch 477/500\n",
      "17037/17037 [==============================] - 8s 488us/step - loss: 207.1546 - mae: 3.6578 - val_loss: 27.2800 - val_mae: 2.4035\n",
      "Epoch 478/500\n",
      "17037/17037 [==============================] - 8s 482us/step - loss: 204.6975 - mae: 3.6516 - val_loss: 11.2155 - val_mae: 1.4546\n",
      "Epoch 479/500\n",
      "17037/17037 [==============================] - 8s 480us/step - loss: 276.3123 - mae: 3.7420 - val_loss: 3.6798 - val_mae: 1.2150\n",
      "Epoch 480/500\n",
      "17037/17037 [==============================] - 8s 493us/step - loss: 231.1028 - mae: 3.6630 - val_loss: 2.3303 - val_mae: 0.9752\n",
      "Epoch 481/500\n",
      "17037/17037 [==============================] - 10s 563us/step - loss: 202.5779 - mae: 3.5623 - val_loss: 2513.9810 - val_mae: 16.6761\n",
      "Epoch 482/500\n",
      "17037/17037 [==============================] - 10s 594us/step - loss: 230.1886 - mae: 3.7010 - val_loss: 651.0759 - val_mae: 8.9029\n",
      "Epoch 483/500\n",
      "17037/17037 [==============================] - 9s 510us/step - loss: 213.1279 - mae: 3.5872 - val_loss: 18.5127 - val_mae: 2.3476\n",
      "Epoch 484/500\n",
      "17037/17037 [==============================] - 9s 523us/step - loss: 221.5453 - mae: 3.6080 - val_loss: 6.9476 - val_mae: 1.5833\n",
      "Epoch 485/500\n",
      "17037/17037 [==============================] - 10s 563us/step - loss: 190.0061 - mae: 3.5836 - val_loss: 23.6017 - val_mae: 2.2484\n",
      "Epoch 486/500\n",
      "17037/17037 [==============================] - 9s 508us/step - loss: 248.4430 - mae: 3.6611 - val_loss: 4.5464 - val_mae: 1.3349\n",
      "Epoch 487/500\n",
      "17037/17037 [==============================] - 9s 510us/step - loss: 177.9463 - mae: 3.5324 - val_loss: 2.8774 - val_mae: 1.2147\n",
      "Epoch 488/500\n",
      "17037/17037 [==============================] - 9s 511us/step - loss: 175.6742 - mae: 3.5565 - val_loss: 86.1775 - val_mae: 4.7986\n",
      "Epoch 489/500\n",
      "17037/17037 [==============================] - 10s 566us/step - loss: 177.1516 - mae: 3.5946 - val_loss: 13.0306 - val_mae: 1.7812\n",
      "Epoch 490/500\n",
      "17037/17037 [==============================] - 9s 534us/step - loss: 247.1878 - mae: 3.6508 - val_loss: 41.0235 - val_mae: 3.2795\n",
      "Epoch 491/500\n",
      "17037/17037 [==============================] - 8s 486us/step - loss: 224.6944 - mae: 3.6057 - val_loss: 21.6461 - val_mae: 2.1812\n",
      "Epoch 492/500\n",
      "17037/17037 [==============================] - 8s 498us/step - loss: 183.2938 - mae: 3.5167 - val_loss: 4.2712 - val_mae: 1.1951\n",
      "Epoch 493/500\n",
      "17037/17037 [==============================] - 11s 660us/step - loss: 242.8065 - mae: 3.5745 - val_loss: 16.8418 - val_mae: 1.8636\n",
      "Epoch 494/500\n",
      "17037/17037 [==============================] - 11s 671us/step - loss: 176.1149 - mae: 3.5616 - val_loss: 6.9922 - val_mae: 1.6607\n",
      "Epoch 495/500\n",
      "17037/17037 [==============================] - 9s 534us/step - loss: 165.2658 - mae: 3.6276 - val_loss: 40.9165 - val_mae: 3.0312\n",
      "Epoch 496/500\n",
      "17037/17037 [==============================] - 10s 603us/step - loss: 183.5760 - mae: 3.5550 - val_loss: 11.2813 - val_mae: 1.9405\n",
      "Epoch 497/500\n",
      "17037/17037 [==============================] - 11s 626us/step - loss: 209.4977 - mae: 3.5829 - val_loss: 3.7192 - val_mae: 1.0133\n",
      "Epoch 498/500\n",
      "17037/17037 [==============================] - 9s 503us/step - loss: 418.2685 - mae: 4.0588 - val_loss: 3.0418 - val_mae: 1.3688\n",
      "Epoch 499/500\n",
      "17037/17037 [==============================] - 9s 509us/step - loss: 243.5632 - mae: 3.6943 - val_loss: 56.5244 - val_mae: 3.6629\n",
      "Epoch 500/500\n",
      "17037/17037 [==============================] - 9s 557us/step - loss: 155.3933 - mae: 3.4470 - val_loss: 7.0121 - val_mae: 1.7060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x230adbb8a00>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 500\n",
    "history = model.fit(train_data, train_label, epochs=EPOCHS, validation_split=0.2, verbose=1)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x230bb1748b0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mae'][50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70596, 18)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"hold_d\"] = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"hold_d\"] = np.round(submission[\"hold_d\"]).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 179,  385,  162, ...,  400, 1390,  981])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['hold_d'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"20211010_dnn2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
